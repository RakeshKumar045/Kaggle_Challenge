{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: MSZoning, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29021279128>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "LotShape         0\n",
       "LandContour      0\n",
       "Utilities        0\n",
       "LotConfig        0\n",
       "LandSlope        0\n",
       "Neighborhood     0\n",
       "Condition1       0\n",
       "Condition2       0\n",
       "BldgType         0\n",
       "HouseStyle       0\n",
       "OverallQual      0\n",
       "OverallCond      0\n",
       "YearBuilt        0\n",
       "YearRemodAdd     0\n",
       "RoofStyle        0\n",
       "RoofMatl         0\n",
       "Exterior1st      0\n",
       "Exterior2nd      0\n",
       "MasVnrType       8\n",
       "MasVnrArea       8\n",
       "ExterQual        0\n",
       "ExterCond        0\n",
       "Foundation       0\n",
       "BsmtQual         0\n",
       "BsmtCond         0\n",
       "                ..\n",
       "BsmtFullBath     0\n",
       "BsmtHalfBath     0\n",
       "FullBath         0\n",
       "HalfBath         0\n",
       "BedroomAbvGr     0\n",
       "KitchenAbvGr     0\n",
       "KitchenQual      0\n",
       "TotRmsAbvGrd     0\n",
       "Functional       0\n",
       "Fireplaces       0\n",
       "FireplaceQu      0\n",
       "GarageType       0\n",
       "GarageFinish     0\n",
       "GarageCars       0\n",
       "GarageArea       0\n",
       "GarageQual       0\n",
       "GarageCond       0\n",
       "PavedDrive       0\n",
       "WoodDeckSF       0\n",
       "OpenPorchSF      0\n",
       "EnclosedPorch    0\n",
       "3SsnPorch        0\n",
       "ScreenPorch      0\n",
       "PoolArea         0\n",
       "MiscVal          0\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x290200fa3c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29021266710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope    ...    EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl    ...                0         0           0   \n",
       "1    AllPub       FR2       Gtl    ...                0         0           0   \n",
       "2    AllPub    Inside       Gtl    ...                0         0           0   \n",
       "3    AllPub    Corner       Gtl    ...              272         0           0   \n",
       "4    AllPub       FR2       Gtl    ...                0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope      ...      OpenPorchSF EnclosedPorch  \\\n",
       "0    AllPub    Inside       Gtl      ...                0             0   \n",
       "1    AllPub    Corner       Gtl      ...               36             0   \n",
       "2    AllPub    Inside       Gtl      ...               34             0   \n",
       "3    AllPub    Inside       Gtl      ...               36             0   \n",
       "4    AllPub    Inside       Gtl      ...               82             0   \n",
       "\n",
       "  3SsnPorch ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType  \\\n",
       "0         0         120        0        0       6    2010        WD   \n",
       "1         0           0        0    12500       6    2010        WD   \n",
       "2         0           0        0        0       3    2010        WD   \n",
       "3         0           0        0        0       6    2010        WD   \n",
       "4         0         144        0        0       1    2010        WD   \n",
       "\n",
       "  SaleCondition  \n",
       "0        Normal  \n",
       "1        Normal  \n",
       "2        Normal  \n",
       "3        Normal  \n",
       "4        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "5       143000.0\n",
       "6       307000.0\n",
       "7       200000.0\n",
       "8       129900.0\n",
       "9       118000.0\n",
       "10      129500.0\n",
       "11      345000.0\n",
       "12      144000.0\n",
       "13      279500.0\n",
       "14      157000.0\n",
       "15      132000.0\n",
       "16      149000.0\n",
       "18      159000.0\n",
       "19      139000.0\n",
       "20      325300.0\n",
       "21      139400.0\n",
       "22      230000.0\n",
       "23      129900.0\n",
       "24      154000.0\n",
       "25      256300.0\n",
       "26      134800.0\n",
       "27      306000.0\n",
       "28      207500.0\n",
       "29       68500.0\n",
       "30       40000.0\n",
       "          ...   \n",
       "1429         NaN\n",
       "1430         NaN\n",
       "1431         NaN\n",
       "1432         NaN\n",
       "1433         NaN\n",
       "1434         NaN\n",
       "1435         NaN\n",
       "1436         NaN\n",
       "1437         NaN\n",
       "1438         NaN\n",
       "1439         NaN\n",
       "1440         NaN\n",
       "1441         NaN\n",
       "1442         NaN\n",
       "1443         NaN\n",
       "1444         NaN\n",
       "1445         NaN\n",
       "1446         NaN\n",
       "1447         NaN\n",
       "1448         NaN\n",
       "1449         NaN\n",
       "1450         NaN\n",
       "1451         NaN\n",
       "1452         NaN\n",
       "1453         NaN\n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>796</td>\n",
       "      <td>566</td>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1107</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>859.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1022</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>851.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1182</td>\n",
       "      <td>1142</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1158</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>188.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>234.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>649</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>967</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1060</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>576</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>909.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>616</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0          856       854          0             3       706.0         0.0   \n",
       "1         1262         0          0             3       978.0         0.0   \n",
       "2          920       866          0             3       486.0         0.0   \n",
       "3          961       756          0             3       216.0         0.0   \n",
       "4         1145      1053          0             4       655.0         0.0   \n",
       "5          796       566        320             1       732.0         0.0   \n",
       "6         1694         0          0             3      1369.0         0.0   \n",
       "7         1107       983          0             3       859.0        32.0   \n",
       "8         1022       752          0             2         0.0         0.0   \n",
       "9         1077         0          0             2       851.0         0.0   \n",
       "10        1040         0          0             3       906.0         0.0   \n",
       "11        1182      1142          0             4       998.0         0.0   \n",
       "12         912         0          0             2       737.0         0.0   \n",
       "13        1494         0          0             3         0.0         0.0   \n",
       "14        1253         0          0             2       733.0         0.0   \n",
       "15         854         0          0             2         0.0         0.0   \n",
       "16        1004         0          0             2       578.0         0.0   \n",
       "18        1114         0          0             3       646.0         0.0   \n",
       "19        1339         0          0             3       504.0         0.0   \n",
       "20        1158      1218          0             4         0.0         0.0   \n",
       "21        1108         0          0             3         0.0         0.0   \n",
       "22        1795         0          0             3         0.0         0.0   \n",
       "23        1060         0          0             3       840.0         0.0   \n",
       "24        1060         0          0             3       188.0       668.0   \n",
       "25        1600         0          0             3         0.0         0.0   \n",
       "26         900         0          0             3       234.0       486.0   \n",
       "27        1704         0          0             3      1218.0         0.0   \n",
       "28        1600         0          0             2      1277.0         0.0   \n",
       "29         520         0          0             1         0.0         0.0   \n",
       "30         649       668          0             3         0.0         0.0   \n",
       "...        ...       ...        ...           ...         ...         ...   \n",
       "1429       641         0          0             2         0.0         0.0   \n",
       "1430       967       671          0             4         0.0         0.0   \n",
       "1431       729         0          0             2         0.0         0.0   \n",
       "1432      1060       336          0             4         0.0         0.0   \n",
       "1433       576       360          0             2         0.0         0.0   \n",
       "1434      1778         0          0             2      1573.0         0.0   \n",
       "1435      1646         0          0             2      1564.0         0.0   \n",
       "1436      1625         0          0             3       776.0         0.0   \n",
       "1437      1664         0          0             4         0.0         0.0   \n",
       "1438      1491         0          0             3         0.0         0.0   \n",
       "1439      1210         0          0             3       576.0         0.0   \n",
       "1440      1650         0          0             2       909.0         0.0   \n",
       "1441      1403         0          0             2      1136.0       116.0   \n",
       "1442      1960         0          0             3      1350.0         0.0   \n",
       "1443      1838         0          0             3      1455.0         0.0   \n",
       "1444      1600         0          0             3         0.0         0.0   \n",
       "1445      1368         0          0             2      1243.0         0.0   \n",
       "1446       616       688          0             3         0.0         0.0   \n",
       "1447       874         0          0             3       441.0         0.0   \n",
       "1448      1652         0          0             4       149.0         0.0   \n",
       "1449       630         0          0             1       522.0         0.0   \n",
       "1450       546       546          0             3       252.0         0.0   \n",
       "1451      1360         0          0             3       119.0       344.0   \n",
       "1452       546       546          0             3       408.0         0.0   \n",
       "1453       546       546          0             3         0.0         0.0   \n",
       "1454       546       546          0             3         0.0         0.0   \n",
       "1455       546       546          0             3       252.0         0.0   \n",
       "1456      1224         0          0             4      1224.0         0.0   \n",
       "1457       970         0          0             3       337.0         0.0   \n",
       "1458       996      1004          0             3       758.0         0.0   \n",
       "\n",
       "      BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  \\\n",
       "0              1.0           0.0      150.0              0 ...     0     0   \n",
       "1              0.0           1.0      284.0              0 ...     0     0   \n",
       "2              1.0           0.0      434.0              0 ...     0     0   \n",
       "3              1.0           0.0      540.0            272 ...     0     0   \n",
       "4              1.0           0.0      490.0              0 ...     0     0   \n",
       "5              1.0           0.0       64.0              0 ...     0     0   \n",
       "6              1.0           0.0      317.0              0 ...     0     0   \n",
       "7              1.0           0.0      216.0            228 ...     0     0   \n",
       "8              0.0           0.0      952.0            205 ...     1     0   \n",
       "9              1.0           0.0      140.0              0 ...     0     0   \n",
       "10             1.0           0.0      134.0              0 ...     0     0   \n",
       "11             1.0           0.0      177.0              0 ...     0     0   \n",
       "12             1.0           0.0      175.0              0 ...     0     0   \n",
       "13             0.0           0.0     1494.0              0 ...     0     0   \n",
       "14             1.0           0.0      520.0            176 ...     0     0   \n",
       "15             0.0           0.0      832.0              0 ...     0     0   \n",
       "16             1.0           0.0      426.0              0 ...     0     0   \n",
       "18             1.0           0.0      468.0              0 ...     0     0   \n",
       "19             0.0           0.0      525.0              0 ...     1     0   \n",
       "20             0.0           0.0     1158.0              0 ...     0     0   \n",
       "21             0.0           0.0      637.0            205 ...     0     0   \n",
       "22             0.0           0.0     1777.0              0 ...     0     0   \n",
       "23             1.0           0.0      200.0              0 ...     0     0   \n",
       "24             1.0           0.0      204.0              0 ...     0     0   \n",
       "25             0.0           0.0     1566.0              0 ...     0     0   \n",
       "26             0.0           1.0      180.0              0 ...     0     0   \n",
       "27             1.0           0.0      486.0              0 ...     0     0   \n",
       "28             1.0           0.0      207.0              0 ...     0     0   \n",
       "29             0.0           0.0      520.0             87 ...     0     0   \n",
       "30             0.0           0.0      649.0            172 ...     0     0   \n",
       "...            ...           ...        ...            ... ...   ...   ...   \n",
       "1429           0.0           0.0      641.0             70 ...     0     0   \n",
       "1430           0.0           0.0      967.0              0 ...     0     0   \n",
       "1431           0.0           0.0        0.0             23 ...     0     0   \n",
       "1432           0.0           0.0      660.0              0 ...     0     1   \n",
       "1433           0.0           0.0      216.0              0 ...     0     0   \n",
       "1434           2.0           0.0        0.0              0 ...     0     0   \n",
       "1435           1.0           1.0       30.0              0 ...     0     0   \n",
       "1436           0.0           1.0      849.0              0 ...     0     0   \n",
       "1437           0.0           0.0     1664.0              0 ...     0     0   \n",
       "1438           0.0           0.0     1491.0              0 ...     0     0   \n",
       "1439           1.0           0.0      552.0              0 ...     0     0   \n",
       "1440           1.0           0.0      723.0              0 ...     0     0   \n",
       "1441           1.0           0.0      129.0              0 ...     0     0   \n",
       "1442           1.0           0.0      378.0              0 ...     0     0   \n",
       "1443           1.0           0.0      383.0              0 ...     0     0   \n",
       "1444           0.0           0.0        0.0            135 ...     0     0   \n",
       "1445           2.0           0.0       45.0              0 ...     0     0   \n",
       "1446           0.0           0.0      264.0              0 ...     0     0   \n",
       "1447           1.0           0.0      423.0              0 ...     0     0   \n",
       "1448           0.0           0.0     1503.0              0 ...     0     0   \n",
       "1449           1.0           0.0      108.0              0 ...     0     0   \n",
       "1450           0.0           0.0      294.0              0 ...     0     0   \n",
       "1451           1.0           0.0      641.0              0 ...     0     0   \n",
       "1452           0.0           0.0      138.0              0 ...     0     0   \n",
       "1453           0.0           0.0      546.0              0 ...     0     0   \n",
       "1454           0.0           0.0      546.0              0 ...     0     0   \n",
       "1455           0.0           0.0      294.0              0 ...     0     0   \n",
       "1456           1.0           0.0        0.0              0 ...     0     0   \n",
       "1457           0.0           1.0      575.0              0 ...     0     0   \n",
       "1458           0.0           0.0      238.0              0 ...     0     0   \n",
       "\n",
       "      Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1       1        0        0        0       0    1  0  \n",
       "1       1       1        0        0        0       0    1  0  \n",
       "2       1       1        0        0        0       0    1  0  \n",
       "3       1       0        0        0        0       1    0  0  \n",
       "4       1       1        0        0        0       0    1  0  \n",
       "5       1       1        0        0        0       0    0  0  \n",
       "6       1       1        0        0        0       0    1  0  \n",
       "7       1       1        0        0        0       0    1  0  \n",
       "8       0       0        0        0        0       1    0  0  \n",
       "9       1       1        0        0        0       0    1  0  \n",
       "10      1       0        0        0        0       1    0  0  \n",
       "11      1       0        0        1        0       0    0  0  \n",
       "12      1       0        0        0        0       1    0  0  \n",
       "13      1       1        0        0        0       0    1  0  \n",
       "14      1       1        0        0        0       0    1  0  \n",
       "15      1       0        0        0        0       1    0  0  \n",
       "16      1       1        0        0        0       0    0  0  \n",
       "18      1       0        0        0        0       1    0  0  \n",
       "19      0       1        0        0        0       0    0  0  \n",
       "20      1       0        0        1        0       0    1  0  \n",
       "21      1       1        0        0        0       0    0  0  \n",
       "22      1       1        0        0        0       0    1  0  \n",
       "23      1       1        0        0        0       0    0  0  \n",
       "24      1       1        0        0        0       0    0  0  \n",
       "25      1       1        0        0        0       0    1  0  \n",
       "26      1       0        0        0        0       1    0  0  \n",
       "27      1       1        0        0        0       0    1  0  \n",
       "28      1       1        0        0        0       0    1  0  \n",
       "29      1       0        0        0        0       1    0  0  \n",
       "30      1       0        0        0        0       1    0  0  \n",
       "...   ...     ...      ...      ...      ...     ...  ... ..  \n",
       "1429    1       0        0        0        0       1    0  0  \n",
       "1430    1       0        0        0        0       1    0  0  \n",
       "1431    0       1        0        0        0       0    0  0  \n",
       "1432    0       1        0        0        0       0    0  0  \n",
       "1433    1       1        0        0        0       0    0  0  \n",
       "1434    1       1        0        0        0       0    0  0  \n",
       "1435    1       1        0        0        0       0    0  0  \n",
       "1436    1       1        0        0        0       0    0  0  \n",
       "1437    1       0        0        0        0       0    0  0  \n",
       "1438    1       1        0        0        0       0    1  0  \n",
       "1439    1       1        0        0        0       0    0  0  \n",
       "1440    1       1        0        0        0       0    0  0  \n",
       "1441    1       1        0        0        0       0    0  0  \n",
       "1442    1       1        0        0        0       0    0  0  \n",
       "1443    1       1        0        0        0       0    0  0  \n",
       "1444    0       1        0        0        0       0    0  0  \n",
       "1445    1       1        0        0        0       0    0  0  \n",
       "1446    1       0        0        1        0       0    1  0  \n",
       "1447    1       1        0        0        0       0    1  0  \n",
       "1448    1       0        0        0        0       0    0  0  \n",
       "1449    1       1        0        0        0       0    0  0  \n",
       "1450    1       1        0        0        0       0    0  0  \n",
       "1451    1       1        0        0        0       0    1  0  \n",
       "1452    1       0        0        0        1       0    0  0  \n",
       "1453    1       1        0        0        0       0    0  0  \n",
       "1454    1       1        0        0        0       0    0  0  \n",
       "1455    1       0        0        0        1       0    0  0  \n",
       "1456    1       0        0        0        0       1    0  0  \n",
       "1457    1       1        0        0        0       0    0  0  \n",
       "1458    1       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "3       961       756          0             3       216.0         0.0   \n",
       "4      1145      1053          0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           1.0           0.0      150.0              0 ...     0     0    1   \n",
       "1           0.0           1.0      284.0              0 ...     0     0    1   \n",
       "2           1.0           0.0      434.0              0 ...     0     0    1   \n",
       "3           1.0           0.0      540.0            272 ...     0     0    1   \n",
       "4           1.0           0.0      490.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1422, 175), (1459, 175))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape, df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciton and selecting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "# classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1422, 174), (1422,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:12:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:13:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints='',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "       n_estimators=900, n_jobs=1, nthread=1, num_parallel_tree=1,\n",
       "       objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1,\n",
       "       tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(df_Test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file( predict_val, filename = \"test\"):\n",
    "    submission_df = pd.read_csv(\"sample_submission.csv\")\n",
    "    print(submission_df.shape)\n",
    "    \n",
    "    submission_df[\"SalePrice\"] = y_pred\n",
    "    submission_df.to_csv(filename + '.csv',index=False)\n",
    "    \n",
    "    return \"Successful file created : \" + filename\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Successful file created : first'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_submission_file( y_pred, filename = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from keras import backend\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# from keras.losses import mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def root_mean_squared_error(y_true, y_pred):\n",
    "#     return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "#both are right root_mean_squared_error\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build_dl_1(X_train_val, y_train_val):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "    # Adding the third hidden layer\n",
    "    model.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    model.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "\n",
    "    # Fitting the ANN to the Training set\n",
    "#     model_history=model.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)\n",
    "    model_history=model.fit(X_train_val, y_train_val,validation_split=0.20, batch_size = 10, nb_epoch = 100)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1137 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 152279.1986 - val_loss: 77337.3219\n",
      "Epoch 2/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 71619.3165 - val_loss: 67171.5980\n",
      "Epoch 3/100\n",
      "1137/1137 [==============================] - 0s 116us/step - loss: 66478.7083 - val_loss: 63588.2307\n",
      "Epoch 4/100\n",
      "1137/1137 [==============================] - 0s 116us/step - loss: 62969.8080 - val_loss: 61043.7709\n",
      "Epoch 5/100\n",
      "1137/1137 [==============================] - 0s 124us/step - loss: 59286.8699 - val_loss: 58552.3455\n",
      "Epoch 6/100\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 55781.3010 - val_loss: 56814.4242\n",
      "Epoch 7/100\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 53189.8198 - val_loss: 54812.3620\n",
      "Epoch 8/100\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 50283.1147 - val_loss: 52755.3247\n",
      "Epoch 9/100\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 48013.5611 - val_loss: 50842.9114\n",
      "Epoch 10/100\n",
      "1137/1137 [==============================] - 0s 126us/step - loss: 45663.9083 - val_loss: 49612.3744\n",
      "Epoch 11/100\n",
      "1137/1137 [==============================] - 0s 122us/step - loss: 43819.3211 - val_loss: 47927.9836\n",
      "Epoch 12/100\n",
      "1137/1137 [==============================] - 0s 130us/step - loss: 40941.7304 - val_loss: 47018.4338\n",
      "Epoch 13/100\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 39798.9181 - val_loss: 46585.5835\n",
      "Epoch 14/100\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 38626.8672 - val_loss: 46121.6571\n",
      "Epoch 15/100\n",
      "1137/1137 [==============================] - 0s 130us/step - loss: 38454.4701 - val_loss: 45283.5667\n",
      "Epoch 16/100\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 37473.3244 - val_loss: 44921.3152\n",
      "Epoch 17/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 37015.2738 - val_loss: 45458.8869\n",
      "Epoch 18/100\n",
      "1137/1137 [==============================] - 0s 119us/step - loss: 36946.8210 - val_loss: 44884.7996\n",
      "Epoch 19/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 36390.9134 - val_loss: 44902.1778\n",
      "Epoch 20/100\n",
      "1137/1137 [==============================] - 0s 126us/step - loss: 36656.4616 - val_loss: 44818.0139\n",
      "Epoch 21/100\n",
      "1137/1137 [==============================] - 0s 117us/step - loss: 36473.6637 - val_loss: 45034.8301\n",
      "Epoch 22/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 36441.5321 - val_loss: 45219.4576\n",
      "Epoch 23/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 36460.3094 - val_loss: 45448.4120\n",
      "Epoch 24/100\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 35976.2140 - val_loss: 45129.4885\n",
      "Epoch 25/100\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 36448.1356 - val_loss: 44712.2529\n",
      "Epoch 26/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 36056.2975 - val_loss: 45079.3758\n",
      "Epoch 27/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 35748.2625 - val_loss: 44683.8897\n",
      "Epoch 28/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 36220.0977 - val_loss: 46708.8979\n",
      "Epoch 29/100\n",
      "1137/1137 [==============================] - 0s 109us/step - loss: 35729.1991 - val_loss: 44926.2810\n",
      "Epoch 30/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 35210.1378 - val_loss: 45022.2143\n",
      "Epoch 31/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 35265.0528 - val_loss: 44608.7009\n",
      "Epoch 32/100\n",
      "1137/1137 [==============================] - 0s 128us/step - loss: 35277.7398 - val_loss: 45359.1107\n",
      "Epoch 33/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 35512.2528 - val_loss: 44439.5752\n",
      "Epoch 34/100\n",
      "1137/1137 [==============================] - 0s 124us/step - loss: 35573.7625 - val_loss: 44410.8242\n",
      "Epoch 35/100\n",
      "1137/1137 [==============================] - 0s 164us/step - loss: 35113.0594 - val_loss: 44422.2079\n",
      "Epoch 36/100\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 35628.7863 - val_loss: 44442.3882\n",
      "Epoch 37/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 35227.5209 - val_loss: 44675.0332\n",
      "Epoch 38/100\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 35431.7764 - val_loss: 44226.5475\n",
      "Epoch 39/100\n",
      "1137/1137 [==============================] - 0s 123us/step - loss: 34762.5971 - val_loss: 49088.0038\n",
      "Epoch 40/100\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 35825.6452 - val_loss: 44326.6555\n",
      "Epoch 41/100\n",
      "1137/1137 [==============================] - 0s 131us/step - loss: 34949.5447 - val_loss: 44425.2525\n",
      "Epoch 42/100\n",
      "1137/1137 [==============================] - 0s 110us/step - loss: 35034.6834 - val_loss: 44271.0721\n",
      "Epoch 43/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 35084.4800 - val_loss: 44255.7341\n",
      "Epoch 44/100\n",
      "1137/1137 [==============================] - 0s 114us/step - loss: 35104.8991 - val_loss: 45037.1536\n",
      "Epoch 45/100\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 34828.2454 - val_loss: 44833.4448\n",
      "Epoch 46/100\n",
      "1137/1137 [==============================] - 0s 127us/step - loss: 34850.1046 - val_loss: 44239.8232\n",
      "Epoch 47/100\n",
      "1137/1137 [==============================] - 0s 109us/step - loss: 34328.8181 - val_loss: 44358.4718\n",
      "Epoch 48/100\n",
      "1137/1137 [==============================] - 0s 126us/step - loss: 34136.6207 - val_loss: 44199.0003\n",
      "Epoch 49/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 34550.1958 - val_loss: 44087.0802\n",
      "Epoch 50/100\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 35037.9363 - val_loss: 44029.1228\n",
      "Epoch 51/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 34456.3657 - val_loss: 43947.9525\n",
      "Epoch 52/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 34599.9705 - val_loss: 44962.5532\n",
      "Epoch 53/100\n",
      "1137/1137 [==============================] - 0s 129us/step - loss: 34796.0174 - val_loss: 44103.5835\n",
      "Epoch 54/100\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 34810.7282 - val_loss: 44535.5652\n",
      "Epoch 55/100\n",
      "1137/1137 [==============================] - 0s 131us/step - loss: 34038.8623 - val_loss: 44163.3649\n",
      "Epoch 56/100\n",
      "1137/1137 [==============================] - 0s 126us/step - loss: 34582.0687 - val_loss: 44318.3351\n",
      "Epoch 57/100\n",
      "1137/1137 [==============================] - 0s 176us/step - loss: 34430.9275 - val_loss: 44065.8519\n",
      "Epoch 58/100\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 34309.2880 - val_loss: 44048.9875\n",
      "Epoch 59/100\n",
      "1137/1137 [==============================] - 0s 123us/step - loss: 34174.9501 - val_loss: 44286.7885\n",
      "Epoch 60/100\n",
      "1137/1137 [==============================] - 0s 195us/step - loss: 34382.7826 - val_loss: 44026.5434\n",
      "Epoch 61/100\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 34180.6758 - val_loss: 44927.8573\n",
      "Epoch 62/100\n",
      "1137/1137 [==============================] - 0s 123us/step - loss: 34012.2069 - val_loss: 44889.8419\n",
      "Epoch 63/100\n",
      "1137/1137 [==============================] - 0s 130us/step - loss: 34128.9121 - val_loss: 46422.8104\n",
      "Epoch 64/100\n",
      "1137/1137 [==============================] - 0s 120us/step - loss: 33728.9523 - val_loss: 44646.1000\n",
      "Epoch 65/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 33679.5066 - val_loss: 44219.4811\n",
      "Epoch 66/100\n",
      "1137/1137 [==============================] - 0s 106us/step - loss: 33930.6720 - val_loss: 44566.4508\n",
      "Epoch 67/100\n",
      "1137/1137 [==============================] - 0s 114us/step - loss: 33765.2903 - val_loss: 44212.3260\n",
      "Epoch 68/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 34047.5358 - val_loss: 44250.8552\n",
      "Epoch 69/100\n",
      "1137/1137 [==============================] - 0s 109us/step - loss: 33797.6826 - val_loss: 44212.9666\n",
      "Epoch 70/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 33516.9284 - val_loss: 44288.0770\n",
      "Epoch 71/100\n",
      "1137/1137 [==============================] - 0s 112us/step - loss: 33610.1705 - val_loss: 45364.9488\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 115us/step - loss: 33594.8065 - val_loss: 45719.5998\n",
      "Epoch 73/100\n",
      "1137/1137 [==============================] - 0s 106us/step - loss: 33230.4960 - val_loss: 44848.5401\n",
      "Epoch 74/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 33566.1026 - val_loss: 44150.2931\n",
      "Epoch 75/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 33185.7390 - val_loss: 44130.9541\n",
      "Epoch 76/100\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 33306.4425 - val_loss: 44173.9915\n",
      "Epoch 77/100\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 33236.3809 - val_loss: 43982.1238\n",
      "Epoch 78/100\n",
      "1137/1137 [==============================] - 0s 119us/step - loss: 32954.2558 - val_loss: 44232.0163\n",
      "Epoch 79/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 32745.1445 - val_loss: 45848.8608\n",
      "Epoch 80/100\n",
      "1137/1137 [==============================] - 0s 103us/step - loss: 33122.7468 - val_loss: 44264.1495\n",
      "Epoch 81/100\n",
      "1137/1137 [==============================] - 0s 112us/step - loss: 33046.6597 - val_loss: 44362.6309\n",
      "Epoch 82/100\n",
      "1137/1137 [==============================] - 0s 117us/step - loss: 32959.4454 - val_loss: 44365.5655\n",
      "Epoch 83/100\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 32826.1044 - val_loss: 44135.5784\n",
      "Epoch 84/100\n",
      "1137/1137 [==============================] - 0s 107us/step - loss: 32849.5957 - val_loss: 45422.7765\n",
      "Epoch 85/100\n",
      "1137/1137 [==============================] - 0s 110us/step - loss: 32944.2929 - val_loss: 44223.9977\n",
      "Epoch 86/100\n",
      "1137/1137 [==============================] - 0s 112us/step - loss: 32910.8755 - val_loss: 44629.7086\n",
      "Epoch 87/100\n",
      "1137/1137 [==============================] - 0s 116us/step - loss: 32465.4973 - val_loss: 44242.2784\n",
      "Epoch 88/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 32618.2089 - val_loss: 44465.9635\n",
      "Epoch 89/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 32743.9154 - val_loss: 44362.2080\n",
      "Epoch 90/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 32503.0046 - val_loss: 45681.7522\n",
      "Epoch 91/100\n",
      "1137/1137 [==============================] - 0s 113us/step - loss: 32533.0042 - val_loss: 44660.1032\n",
      "Epoch 92/100\n",
      "1137/1137 [==============================] - 0s 110us/step - loss: 32378.7772 - val_loss: 44331.0009\n",
      "Epoch 93/100\n",
      "1137/1137 [==============================] - 0s 114us/step - loss: 32731.7108 - val_loss: 44312.9624\n",
      "Epoch 94/100\n",
      "1137/1137 [==============================] - 0s 117us/step - loss: 32055.8805 - val_loss: 45320.2611\n",
      "Epoch 95/100\n",
      "1137/1137 [==============================] - 0s 110us/step - loss: 32195.7390 - val_loss: 44419.5332\n",
      "Epoch 96/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 32086.0580 - val_loss: 44432.3395\n",
      "Epoch 97/100\n",
      "1137/1137 [==============================] - 0s 107us/step - loss: 32440.5528 - val_loss: 44567.2381\n",
      "Epoch 98/100\n",
      "1137/1137 [==============================] - 0s 113us/step - loss: 32552.0489 - val_loss: 44422.6866\n",
      "Epoch 99/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 31975.3086 - val_loss: 44305.7735\n",
      "Epoch 100/100\n",
      "1137/1137 [==============================] - 0s 116us/step - loss: 32348.3550 - val_loss: 44734.3469\n"
     ]
    }
   ],
   "source": [
    "model_build_1 = model_build_dl_1(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = model_build_1.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Successful file created : forth_DL'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_submission_file( y_pred_1, filename = \"forth_DL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build_dl_2(X_train_val, y_train_val):\n",
    "    # Fitting the ANN to the Training set\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape = (X_train.shape[1], ), activation = 'relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    \n",
    "#     model_history = model.fit(X_train_val, y_train_val, epochs=200, batch_size=16, validation_split = 0.001, verbose=0)\n",
    "    \n",
    "    model_history_val = model.fit(X_train_val, y_train_val, epochs=1000, batch_size=16, validation_split = 0.001)\n",
    "    \n",
    "    \n",
    "    #     model_history=model.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)\n",
    "    return model, model_history_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1420 samples, validate on 2 samples\n",
      "Epoch 1/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 2/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 3/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 4/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 5/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 6/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 7/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 8/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 9/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 10/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 11/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 12/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 13/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 14/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 15/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 16/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 17/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 18/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 19/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 20/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 21/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 22/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 23/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 24/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 25/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 26/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 27/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 28/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 29/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 30/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 31/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 32/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 33/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 34/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 35/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 36/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 37/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 38/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 39/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 40/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073100.0789 - val_loss: 20977883136.0000\n",
      "Epoch 41/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 42/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 43/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 44/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 45/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 46/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n",
      "Epoch 47/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 48/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 49/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 50/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 51/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073077.0028 - val_loss: 20977883136.0000\n",
      "Epoch 52/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 53/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 54/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 55/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 56/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 57/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073861.5887 - val_loss: 20977883136.0000\n",
      "Epoch 58/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 59/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 60/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 61/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 62/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 63/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 64/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 65/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 67/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 68/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777072990.4676 - val_loss: 20977883136.0000\n",
      "Epoch 69/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 70/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073751.9775 - val_loss: 20977883136.0000\n",
      "Epoch 71/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 72/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 73/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 74/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 75/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 76/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 77/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 78/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 79/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073861.5887 - val_loss: 20977883136.0000\n",
      "Epoch 80/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 81/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 82/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 83/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 84/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 85/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 86/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 87/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 88/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 89/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 90/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 91/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39461884660.869 - 0s 66us/step - loss: 39777073607.7521 - val_loss: 20977883136.0000\n",
      "Epoch 92/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 93/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 94/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 95/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 96/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073671.2113 - val_loss: 20977883136.0000\n",
      "Epoch 97/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 98/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 99/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 100/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 101/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 102/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073111.6169 - val_loss: 20977883136.0000\n",
      "Epoch 103/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073267.3803 - val_loss: 20977883136.0000\n",
      "Epoch 104/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 105/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 106/1000\n",
      "1420/1420 [==============================] - 0s 105us/step - loss: 39777073169.3070 - val_loss: 20977883136.0000\n",
      "Epoch 107/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 108/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 109/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 110/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 111/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 112/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073169.3070 - val_loss: 20977883136.0000\n",
      "Epoch 113/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 114/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 115/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 116/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 117/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073111.6169 - val_loss: 20977883136.0000\n",
      "Epoch 118/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 119/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 120/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 121/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 122/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 123/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 124/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 125/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 126/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073169.3070 - val_loss: 20977883136.0000\n",
      "Epoch 127/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 128/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 129/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 130/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 131/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 132/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073613.5211 - val_loss: 20977883136.0000\n",
      "Epoch 133/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 134/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 135/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 136/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 137/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 138/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073850.0507 - val_loss: 20977883136.0000\n",
      "Epoch 139/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 140/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 141/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 142/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 143/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 144/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 41142772352.000 - 0s 68us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 145/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 146/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 147/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 148/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 149/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n",
      "Epoch 150/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 151/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 152/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 153/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 154/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073705.8254 - val_loss: 20977883136.0000\n",
      "Epoch 155/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 156/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 157/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 158/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 159/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073221.2282 - val_loss: 20977883136.0000\n",
      "Epoch 160/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 161/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 162/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 163/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 164/1000\n",
      "1420/1420 [==============================] - 0s 114us/step - loss: 39777073088.5408 - val_loss: 20977883136.0000\n",
      "Epoch 165/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 166/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 167/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 168/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073232.7662 - val_loss: 20977883136.0000\n",
      "Epoch 169/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073163.5380 - val_loss: 20977883136.0000\n",
      "Epoch 170/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 171/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 172/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 173/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 174/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 175/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 176/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073873.1268 - val_loss: 20977883136.0000\n",
      "Epoch 177/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 178/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 179/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 180/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 181/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073821.2056 - val_loss: 20977883136.0000\n",
      "Epoch 182/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 183/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 184/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 185/1000\n",
      "1420/1420 [==============================] - 0s 90us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 186/1000\n",
      "1420/1420 [==============================] - 0s 105us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 187/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073625.0592 - val_loss: 20977883136.0000\n",
      "Epoch 188/1000\n",
      "1420/1420 [==============================] - 0s 124us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 189/1000\n",
      "1420/1420 [==============================] - 0s 128us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 190/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 191/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 192/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 193/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 107us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 195/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 196/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 197/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 198/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 199/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 200/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777072990.4676 - val_loss: 20977883136.0000\n",
      "Epoch 201/1000\n",
      "1420/1420 [==============================] - 0s 58us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 202/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 203/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 204/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 205/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 206/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 207/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 208/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073694.2873 - val_loss: 20977883136.0000\n",
      "Epoch 209/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 210/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n",
      "Epoch 211/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073942.3549 - val_loss: 20977883136.0000\n",
      "Epoch 212/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 213/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073861.5887 - val_loss: 20977883136.0000\n",
      "Epoch 214/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 215/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 216/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 217/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 218/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 219/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 220/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 221/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 222/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 223/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 224/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 225/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 226/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 227/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 228/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 229/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 230/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 231/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 232/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 233/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 234/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 235/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 236/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 237/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 238/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 239/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 240/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073140.4620 - val_loss: 20977883136.0000\n",
      "Epoch 241/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 242/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073780.8225 - val_loss: 20977883136.0000\n",
      "Epoch 243/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 244/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n",
      "Epoch 245/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 246/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 247/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 248/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 249/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 250/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073659.6732 - val_loss: 20977883136.0000\n",
      "Epoch 251/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 252/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 253/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 254/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 255/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073694.2873 - val_loss: 20977883136.0000\n",
      "Epoch 256/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 257/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 258/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073590.4451 - val_loss: 20977883136.0000\n",
      "Epoch 259/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 260/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073053.9268 - val_loss: 20977883136.0000\n",
      "Epoch 261/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073578.9070 - val_loss: 20977883136.0000\n",
      "Epoch 262/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 263/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073803.8986 - val_loss: 20977883136.0000\n",
      "Epoch 264/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 265/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 266/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073163.5380 - val_loss: 20977883136.0000\n",
      "Epoch 267/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 268/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 269/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 270/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777072973.1606 - val_loss: 20977883136.0000\n",
      "Epoch 271/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 272/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 273/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073117.3859 - val_loss: 20977883136.0000\n",
      "Epoch 274/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073100.0789 - val_loss: 20977883136.0000\n",
      "Epoch 275/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073826.9746 - val_loss: 20977883136.0000\n",
      "Epoch 276/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 277/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 278/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 279/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 280/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 281/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 282/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 283/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 284/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 285/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 286/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 287/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 288/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 289/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 290/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39404496329.531 - 0s 67us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 291/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 292/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 293/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 294/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 295/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 296/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 297/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 298/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 299/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 300/1000\n",
      "1420/1420 [==============================] - 0s 59us/step - loss: 39777073625.0592 - val_loss: 20977883136.0000\n",
      "Epoch 301/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 302/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 303/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 304/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 305/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 306/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 307/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 308/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073746.2085 - val_loss: 20977883136.0000\n",
      "Epoch 309/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 310/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 311/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 312/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 313/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 314/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 315/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 316/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 317/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 318/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 319/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 320/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 321/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 323/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 324/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 325/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 326/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 327/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 328/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 329/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 330/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 331/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 332/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073775.0535 - val_loss: 20977883136.0000\n",
      "Epoch 333/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 334/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 335/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 336/1000\n",
      "1420/1420 [==============================] - 0s 112us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 337/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 338/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 339/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 340/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 341/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 342/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 343/1000\n",
      "1420/1420 [==============================] - 0s 59us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 344/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 345/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 346/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 347/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 348/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 349/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 350/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 38890124928.000 - 0s 68us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 351/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 352/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073746.2085 - val_loss: 20977883136.0000\n",
      "Epoch 353/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 354/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 355/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 356/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 357/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 358/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 359/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 360/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 361/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 362/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 363/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 364/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n",
      "Epoch 365/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073267.3803 - val_loss: 20977883136.0000\n",
      "Epoch 366/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 367/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073746.2085 - val_loss: 20977883136.0000\n",
      "Epoch 368/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 369/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073290.4563 - val_loss: 20977883136.0000\n",
      "Epoch 370/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 371/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073578.9070 - val_loss: 20977883136.0000\n",
      "Epoch 372/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 373/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 374/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 375/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 376/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 377/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 378/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 379/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073740.4394 - val_loss: 20977883136.0000\n",
      "Epoch 380/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 381/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 382/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 383/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 384/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 385/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 387/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 388/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 389/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 390/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 391/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 392/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 393/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 394/1000\n",
      "1420/1420 [==============================] - 0s 112us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 395/1000\n",
      "1420/1420 [==============================] - 0s 114us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 396/1000\n",
      "1420/1420 [==============================] - 0s 114us/step - loss: 39777073105.8479 - val_loss: 20977883136.0000\n",
      "Epoch 397/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073077.0028 - val_loss: 20977883136.0000\n",
      "Epoch 398/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 399/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 400/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 401/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073221.2282 - val_loss: 20977883136.0000\n",
      "Epoch 402/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 403/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 404/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 405/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 406/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 407/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 408/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 409/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 410/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073613.5211 - val_loss: 20977883136.0000\n",
      "Epoch 411/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 412/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 413/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 414/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 415/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 416/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 417/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 418/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 419/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 420/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 421/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 422/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073792.3606 - val_loss: 20977883136.0000\n",
      "Epoch 423/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 424/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 425/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073192.3831 - val_loss: 20977883136.0000\n",
      "Epoch 426/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 427/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 428/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073740.4394 - val_loss: 20977883136.0000\n",
      "Epoch 429/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 430/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 431/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 432/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 433/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 434/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 435/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 436/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 437/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 438/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 439/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 440/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 441/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 442/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 443/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 444/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 445/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 446/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 447/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 448/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 449/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 450/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 90us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 451/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 452/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 453/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073815.4366 - val_loss: 20977883136.0000\n",
      "Epoch 454/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 455/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 456/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777072996.2366 - val_loss: 20977883136.0000\n",
      "Epoch 457/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 458/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 459/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 460/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 461/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 462/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073186.6141 - val_loss: 20977883136.0000\n",
      "Epoch 463/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 464/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 465/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 466/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 467/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 468/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 469/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 470/1000\n",
      "1420/1420 [==============================] - 0s 102us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 471/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 472/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n",
      "Epoch 473/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 474/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 475/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 476/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 477/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 478/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 479/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 480/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 481/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 482/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 483/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 484/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 485/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 486/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 487/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 488/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 489/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 490/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073221.2282 - val_loss: 20977883136.0000\n",
      "Epoch 491/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073717.3634 - val_loss: 20977883136.0000\n",
      "Epoch 492/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 493/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 494/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 495/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 496/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 497/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 498/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 499/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39604551013.783 - 0s 79us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 500/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 501/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 502/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 503/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 504/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 505/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073740.4394 - val_loss: 20977883136.0000\n",
      "Epoch 506/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 507/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 508/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 509/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 510/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 511/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 512/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 513/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 514/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 515/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 516/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 517/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 518/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 519/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 520/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073694.2873 - val_loss: 20977883136.0000\n",
      "Epoch 521/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 522/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073019.3127 - val_loss: 20977883136.0000\n",
      "Epoch 523/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 524/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 525/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 526/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073221.2282 - val_loss: 20977883136.0000\n",
      "Epoch 527/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 528/1000\n",
      "1420/1420 [==============================] - 0s 90us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 529/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 530/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 531/1000\n",
      "1420/1420 [==============================] - 0s 99us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 532/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 533/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 534/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 535/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 536/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 537/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 538/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073671.2113 - val_loss: 20977883136.0000\n",
      "Epoch 539/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073838.5127 - val_loss: 20977883136.0000\n",
      "Epoch 540/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 541/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073152.0000 - val_loss: 20977883136.0000\n",
      "Epoch 542/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073746.2085 - val_loss: 20977883136.0000\n",
      "Epoch 543/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 544/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 545/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 546/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 547/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 548/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 549/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 550/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 551/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 552/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 553/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 554/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 555/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 556/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 557/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073065.4648 - val_loss: 20977883136.0000\n",
      "Epoch 558/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 559/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 560/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 561/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 562/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 563/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 564/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 565/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 566/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073325.0704 - val_loss: 20977883136.0000\n",
      "Epoch 567/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 568/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 569/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 570/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 571/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 572/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073163.5380 - val_loss: 20977883136.0000\n",
      "Epoch 573/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 574/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 575/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073192.3831 - val_loss: 20977883136.0000\n",
      "Epoch 576/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 577/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 578/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 579/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 580/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 581/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 582/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073105.8479 - val_loss: 20977883136.0000\n",
      "Epoch 583/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 584/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 585/1000\n",
      "1420/1420 [==============================] - 0s 105us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 586/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 587/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 588/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073613.5211 - val_loss: 20977883136.0000\n",
      "Epoch 589/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 590/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 591/1000\n",
      "1420/1420 [==============================] - 0s 117us/step - loss: 39777073244.3042 - val_loss: 20977883136.0000\n",
      "Epoch 592/1000\n",
      "1420/1420 [==============================] - 0s 136us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 593/1000\n",
      "1420/1420 [==============================] - 0s 134us/step - loss: 39777073169.3070 - val_loss: 20977883136.0000\n",
      "Epoch 594/1000\n",
      "1420/1420 [==============================] - 0s 102us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 595/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 596/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 597/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 598/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 599/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073682.7493 - val_loss: 20977883136.0000\n",
      "Epoch 600/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 601/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 602/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 603/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 604/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 605/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 606/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073613.5211 - val_loss: 20977883136.0000\n",
      "Epoch 607/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 608/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 609/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 610/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39483520105.025 - 0s 84us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 611/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 612/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 613/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 614/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 615/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 616/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 617/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 618/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 619/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 620/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 621/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 622/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 623/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 624/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 625/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 626/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 627/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 628/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 629/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073192.3831 - val_loss: 20977883136.0000\n",
      "Epoch 630/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 631/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 632/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 633/1000\n",
      "1420/1420 [==============================] - 0s 118us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 634/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 635/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 636/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 637/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 638/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 639/1000\n",
      "1420/1420 [==============================] - 0s 130us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 640/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 641/1000\n",
      "1420/1420 [==============================] - 0s 110us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 139us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 643/1000\n",
      "1420/1420 [==============================] - 0s 130us/step - loss: 39777073053.9268 - val_loss: 20977883136.0000\n",
      "Epoch 644/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 645/1000\n",
      "1420/1420 [==============================] - 0s 119us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 646/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 647/1000\n",
      "1420/1420 [==============================] - 0s 159us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 648/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 649/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 650/1000\n",
      "1420/1420 [==============================] - 0s 120us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 651/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 652/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 653/1000\n",
      "1420/1420 [==============================] - 0s 90us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 654/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073873.1268 - val_loss: 20977883136.0000\n",
      "Epoch 655/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 656/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 657/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 658/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073838.5127 - val_loss: 20977883136.0000\n",
      "Epoch 659/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073607.7521 - val_loss: 20977883136.0000\n",
      "Epoch 660/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 661/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073209.6901 - val_loss: 20977883136.0000\n",
      "Epoch 662/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 663/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073578.9070 - val_loss: 20977883136.0000\n",
      "Epoch 664/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 665/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 666/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 667/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 668/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 669/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 670/1000\n",
      "1420/1420 [==============================] - 0s 59us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 671/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 672/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073780.8225 - val_loss: 20977883136.0000\n",
      "Epoch 673/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 674/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 675/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 676/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 677/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39410014129.230 - 0s 66us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 678/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073088.5408 - val_loss: 20977883136.0000\n",
      "Epoch 679/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 680/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 681/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 682/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 683/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 684/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 685/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 686/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 687/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 688/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 689/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 690/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40639632856.615 - 0s 62us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 691/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 692/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 693/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073244.3042 - val_loss: 20977883136.0000\n",
      "Epoch 694/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073244.3042 - val_loss: 20977883136.0000\n",
      "Epoch 695/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 696/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 697/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073850.0507 - val_loss: 20977883136.0000\n",
      "Epoch 698/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 699/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 700/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40259704477.538 - 0s 63us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 701/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 702/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 703/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 704/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 705/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 706/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073682.7493 - val_loss: 20977883136.0000\n",
      "Epoch 707/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 708/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 709/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 710/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 711/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 712/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 713/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 714/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 715/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 716/1000\n",
      "1420/1420 [==============================] - 0s 133us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 717/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 718/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 719/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 720/1000\n",
      "1420/1420 [==============================] - 0s 115us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 721/1000\n",
      "1420/1420 [==============================] - 0s 115us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 722/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 723/1000\n",
      "1420/1420 [==============================] - 0s 131us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 724/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 725/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073775.0535 - val_loss: 20977883136.0000\n",
      "Epoch 726/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 727/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073192.3831 - val_loss: 20977883136.0000\n",
      "Epoch 728/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073671.2113 - val_loss: 20977883136.0000\n",
      "Epoch 729/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 730/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 731/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 732/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 733/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 734/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 735/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 736/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073267.3803 - val_loss: 20977883136.0000\n",
      "Epoch 737/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 738/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 739/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 740/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40081240309.760 - 0s 64us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 741/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 742/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073088.5408 - val_loss: 20977883136.0000\n",
      "Epoch 743/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 744/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 745/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 746/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 747/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 748/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 749/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 750/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 751/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 752/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073728.9014 - val_loss: 20977883136.0000\n",
      "Epoch 753/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 754/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 755/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 756/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 757/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 758/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 759/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 760/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 761/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 762/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 763/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 764/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073780.8225 - val_loss: 20977883136.0000\n",
      "Epoch 765/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 766/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 767/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 768/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 769/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 771/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 772/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 773/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 774/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 775/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 776/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 777/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 778/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 779/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 780/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073186.6141 - val_loss: 20977883136.0000\n",
      "Epoch 781/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 782/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 783/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 784/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 785/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 786/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 787/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 788/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073105.8479 - val_loss: 20977883136.0000\n",
      "Epoch 789/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 790/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 791/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 792/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 793/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 794/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 795/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 796/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 797/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 798/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 38888196411.076 - 0s 63us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 799/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 800/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 801/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 802/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 803/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 804/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 805/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073590.4451 - val_loss: 20977883136.0000\n",
      "Epoch 806/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 807/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073578.9070 - val_loss: 20977883136.0000\n",
      "Epoch 808/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 809/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 810/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 811/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 812/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 813/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 814/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073287.5718 - val_loss: 20977883136.0000\n",
      "Epoch 815/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 816/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39968970872.470 - 0s 65us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 817/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 818/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 819/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 820/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 821/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39203724051.692 - 0s 65us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 822/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 823/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073100.0789 - val_loss: 20977883136.0000\n",
      "Epoch 824/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 825/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 826/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 827/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 828/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073815.4366 - val_loss: 20977883136.0000\n",
      "Epoch 829/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 830/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 831/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 832/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 833/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073803.8986 - val_loss: 20977883136.0000\n",
      "Epoch 835/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40187343169.254 - 0s 63us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 836/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073873.1268 - val_loss: 20977883136.0000\n",
      "Epoch 837/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 838/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 839/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 840/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 841/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 842/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 843/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 38950301985.811 - 0s 65us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 844/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 845/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39720669962.240 - 0s 68us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 846/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 847/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073244.3042 - val_loss: 20977883136.0000\n",
      "Epoch 848/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 849/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 850/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 851/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 852/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 853/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 854/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 855/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073209.6901 - val_loss: 20977883136.0000\n",
      "Epoch 856/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 857/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073019.3127 - val_loss: 20977883136.0000\n",
      "Epoch 858/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 859/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 860/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 861/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39902246144.000 - 0s 67us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 862/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 863/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 864/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073100.0789 - val_loss: 20977883136.0000\n",
      "Epoch 865/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073567.3690 - val_loss: 20977883136.0000\n",
      "Epoch 866/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 867/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 868/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 869/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 870/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 871/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 872/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 873/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 874/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 875/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 876/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073325.0704 - val_loss: 20977883136.0000\n",
      "Epoch 877/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073053.9268 - val_loss: 20977883136.0000\n",
      "Epoch 878/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 879/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 880/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 881/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 882/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 883/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 884/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 885/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 886/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 887/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 888/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 889/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 890/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 891/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 892/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 893/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 894/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 895/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 896/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073498.1408 - val_loss: 20977883136.0000\n",
      "Epoch 898/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 899/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40553613430.153 - 0s 62us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 900/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 901/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 902/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 903/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 904/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073059.6958 - val_loss: 20977883136.0000\n",
      "Epoch 905/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 906/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 907/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 908/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073567.3690 - val_loss: 20977883136.0000\n",
      "Epoch 909/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 910/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 911/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 912/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 913/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 914/1000\n",
      "1420/1420 [==============================] - 0s 164us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 915/1000\n",
      "1420/1420 [==============================] - 0s 123us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 916/1000\n",
      "1420/1420 [==============================] - 0s 110us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 917/1000\n",
      "1420/1420 [==============================] - 0s 105us/step - loss: 39777073042.3887 - val_loss: 20977883136.0000\n",
      "Epoch 918/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 919/1000\n",
      "1420/1420 [==============================] - 0s 119us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 920/1000\n",
      "1420/1420 [==============================] - 0s 122us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 921/1000\n",
      "1420/1420 [==============================] - 0s 131us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 922/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073907.7408 - val_loss: 20977883136.0000\n",
      "Epoch 923/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 924/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 925/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 926/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 927/1000\n",
      "1420/1420 [==============================] - 0s 108us/step - loss: 39777073048.1577 - val_loss: 20977883136.0000\n",
      "Epoch 928/1000\n",
      "1420/1420 [==============================] - 0s 164us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 929/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 930/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073111.6169 - val_loss: 20977883136.0000\n",
      "Epoch 931/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 932/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 933/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 934/1000\n",
      "1420/1420 [==============================] - 0s 106us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 935/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 936/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 937/1000\n",
      "1420/1420 [==============================] - 0s 106us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 938/1000\n",
      "1420/1420 [==============================] - 0s 110us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 939/1000\n",
      "1420/1420 [==============================] - 0s 113us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 940/1000\n",
      "1420/1420 [==============================] - 0s 116us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 941/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 942/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 943/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 944/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 945/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 946/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 947/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 948/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 949/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073694.2873 - val_loss: 20977883136.0000\n",
      "Epoch 950/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 951/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073498.1408 - val_loss: 20977883136.0000\n",
      "Epoch 952/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 953/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 954/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 955/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 956/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 957/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073201.0366 - val_loss: 20977883136.0000\n",
      "Epoch 958/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 959/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 960/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 962/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 963/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 964/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 965/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073792.3606 - val_loss: 20977883136.0000\n",
      "Epoch 966/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 967/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073826.9746 - val_loss: 20977883136.0000\n",
      "Epoch 968/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39931749101.268 - 0s 81us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 969/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 970/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 971/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 972/1000\n",
      "1420/1420 [==============================] - 0s 106us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 973/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 974/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073267.3803 - val_loss: 20977883136.0000\n",
      "Epoch 975/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 976/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 977/1000\n",
      "1420/1420 [==============================] - 0s 114us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 978/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n",
      "Epoch 979/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 980/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 981/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 982/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 983/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 984/1000\n",
      "1420/1420 [==============================] - 0s 99us/step - loss: 39777073803.8986 - val_loss: 20977883136.0000\n",
      "Epoch 985/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 986/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 987/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 988/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n",
      "Epoch 989/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 990/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 991/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39727150345.481 - 0s 81us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 992/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 993/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 994/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 995/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 996/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 997/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 998/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 999/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 1000/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n"
     ]
    }
   ],
   "source": [
    "model_build_2, model_history = model_build_dl_2(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = model_build_2.predict(df_Test)\n",
    "create_submission_file( y_pred_2, filename = \"forth_DL_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 128)               22400     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 55,681\n",
      "Trainable params: 55,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_build_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the training data: 39777073123.15493\n"
     ]
    }
   ],
   "source": [
    "print('MSE of the training data: {}' .format(model_history.history['loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29032002198>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'][10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of training data: 39750633017.2609\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_2 = model_build_2.predict(X_train)\n",
    "# print('MSE of training data: {}'.format(mean_squared_error(y_train, y_train_pred_2)))\n",
    "\n",
    "\n",
    "#or\n",
    "y_train_reshape = np.array(y_train).reshape(-1,1)\n",
    "print('MSE of training data: {}'.format(mean_squared_error(y_train_reshape, y_train_pred_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates our Keras model\n",
    "def create_model(optimizer= 'adam' , activation= 'relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(336,), activation=activation))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[\"accuracy\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create a model as a sklearn estimator\n",
    "#     model = KerasClassifier(build_fn=model, epochs=6, batch_size=16, verbose = 0)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model as a sklearn estimator\n",
    "model_hyperparameter = KerasClassifier(build_fn=create_model, epochs=6, batch_size=16, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-7a2e041affdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m                        cv = 10)\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mrandom_search_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# random_search = RandomizedSearchCV(model_hyperparameter, param_distributions=params, cv=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         if (losses.is_categorical_crossentropy(self.model.loss) and\n\u001b[0m\u001b[0;32m    145\u001b[0m                 len(y.shape) != 2):\n\u001b[0;32m    146\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define a series of parameters\n",
    "params = dict(optimizer=['sgd','adam'],batch_size=[16, 32], activation=['relu','tanh', 'sigmoid', 'softmax'])\n",
    "\n",
    "# Create a random search cv object and fit it to the data\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model_hyperparameter,\n",
    "                       param_grid = params,\n",
    "                       scoring = 'accuracy',\n",
    "                       cv = 10)\n",
    "\n",
    "random_search_results = grid_search.fit(X_train, y_train, verbose=0)\n",
    "\n",
    "# random_search = RandomizedSearchCV(model_hyperparameter, param_distributions=params, cv=5)\n",
    "# random_search_results = random_search.fit(X_train, y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
