{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: MSZoning, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f39a635b090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f39a844c910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f39a5a62150>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1454         160         21.0     1936            4            7       1970   \n",
       "1455         160         21.0     1894            4            5       1970   \n",
       "1456          20        160.0    20000            5            7       1960   \n",
       "1457          85         62.0    10441            5            5       1992   \n",
       "1458          60         74.0     9627            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0             2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1             1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2             2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3             1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4             2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "...            ...         ...         ...         ...  ...   ...   ...  ...   \n",
       "1454          1970         0.0         0.0         0.0  ...     0     0    1   \n",
       "1455          1970         0.0       252.0         0.0  ...     0     0    1   \n",
       "1456          1996         0.0      1224.0         0.0  ...     0     0    1   \n",
       "1457          1992         0.0       337.0         0.0  ...     0     0    1   \n",
       "1458          1994        94.0       758.0         0.0  ...     0     0    1   \n",
       "\n",
       "      Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0          1        0        0        0       0    1  0  \n",
       "1          1        0        0        0       0    1  0  \n",
       "2          1        0        0        0       0    1  0  \n",
       "3          0        0        0        0       1    0  0  \n",
       "4          1        0        0        0       0    1  0  \n",
       "...      ...      ...      ...      ...     ...  ... ..  \n",
       "1454       1        0        0        0       0    0  0  \n",
       "1455       0        0        0        1       0    0  0  \n",
       "1456       0        0        0        0       1    0  0  \n",
       "1457       1        0        0        0       0    0  0  \n",
       "1458       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1          1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2          2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3          1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4          2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          1961         0.0       468.0       144.0  ...     0     0    1   \n",
       "1          1958       108.0       923.0         0.0  ...     0     0    1   \n",
       "2          1998         0.0       791.0         0.0  ...     0     0    1   \n",
       "3          1998        20.0       602.0         0.0  ...     0     0    1   \n",
       "4          1992         0.0       263.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1422, 175), (1459, 175))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape, df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciton and selecting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f1b8cdba8b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1422, 174), (1422,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:12:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[04:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:13:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints='',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "       n_estimators=900, n_jobs=1, nthread=1, num_parallel_tree=1,\n",
       "       objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1,\n",
       "       tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(df_Test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file( predict_val, filename = \"test\"):\n",
    "    submission_df = pd.read_csv(\"sample_submission.csv\")\n",
    "    print(submission_df.shape)\n",
    "    \n",
    "    submission_df[\"SalePrice\"] = y_pred\n",
    "    submission_df.to_csv(filename + '.csv',index=False)\n",
    "    \n",
    "    return \"Successful file created : \" + filename\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Successful file created : first'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_submission_file( y_pred, filename = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from keras import backend\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# from keras.losses import mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def root_mean_squared_error(y_true, y_pred):\n",
    "#     return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "#both are right root_mean_squared_error\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build_dl_1(X_train_val, y_train_val):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "    # Adding the third hidden layer\n",
    "    model.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    model.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "\n",
    "    # Fitting the ANN to the Training set\n",
    "#     model_history=model.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)\n",
    "    model_history=model.fit(X_train_val, y_train_val,validation_split=0.20, batch_size = 10, nb_epoch = 100)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1137 samples, validate on 285 samples\n",
      "Epoch 1/100\n",
      "1137/1137 [==============================] - 0s 168us/step - loss: 152279.1986 - val_loss: 77337.3219\n",
      "Epoch 2/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 71619.3165 - val_loss: 67171.5980\n",
      "Epoch 3/100\n",
      "1137/1137 [==============================] - 0s 116us/step - loss: 66478.7083 - val_loss: 63588.2307\n",
      "Epoch 4/100\n",
      "1137/1137 [==============================] - 0s 116us/step - loss: 62969.8080 - val_loss: 61043.7709\n",
      "Epoch 5/100\n",
      "1137/1137 [==============================] - 0s 124us/step - loss: 59286.8699 - val_loss: 58552.3455\n",
      "Epoch 6/100\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 55781.3010 - val_loss: 56814.4242\n",
      "Epoch 7/100\n",
      "1137/1137 [==============================] - 0s 146us/step - loss: 53189.8198 - val_loss: 54812.3620\n",
      "Epoch 8/100\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 50283.1147 - val_loss: 52755.3247\n",
      "Epoch 9/100\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 48013.5611 - val_loss: 50842.9114\n",
      "Epoch 10/100\n",
      "1137/1137 [==============================] - 0s 126us/step - loss: 45663.9083 - val_loss: 49612.3744\n",
      "Epoch 11/100\n",
      "1137/1137 [==============================] - 0s 122us/step - loss: 43819.3211 - val_loss: 47927.9836\n",
      "Epoch 12/100\n",
      "1137/1137 [==============================] - 0s 130us/step - loss: 40941.7304 - val_loss: 47018.4338\n",
      "Epoch 13/100\n",
      "1137/1137 [==============================] - 0s 140us/step - loss: 39798.9181 - val_loss: 46585.5835\n",
      "Epoch 14/100\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 38626.8672 - val_loss: 46121.6571\n",
      "Epoch 15/100\n",
      "1137/1137 [==============================] - 0s 130us/step - loss: 38454.4701 - val_loss: 45283.5667\n",
      "Epoch 16/100\n",
      "1137/1137 [==============================] - 0s 133us/step - loss: 37473.3244 - val_loss: 44921.3152\n",
      "Epoch 17/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 37015.2738 - val_loss: 45458.8869\n",
      "Epoch 18/100\n",
      "1137/1137 [==============================] - 0s 119us/step - loss: 36946.8210 - val_loss: 44884.7996\n",
      "Epoch 19/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 36390.9134 - val_loss: 44902.1778\n",
      "Epoch 20/100\n",
      "1137/1137 [==============================] - 0s 126us/step - loss: 36656.4616 - val_loss: 44818.0139\n",
      "Epoch 21/100\n",
      "1137/1137 [==============================] - 0s 117us/step - loss: 36473.6637 - val_loss: 45034.8301\n",
      "Epoch 22/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 36441.5321 - val_loss: 45219.4576\n",
      "Epoch 23/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 36460.3094 - val_loss: 45448.4120\n",
      "Epoch 24/100\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 35976.2140 - val_loss: 45129.4885\n",
      "Epoch 25/100\n",
      "1137/1137 [==============================] - 0s 145us/step - loss: 36448.1356 - val_loss: 44712.2529\n",
      "Epoch 26/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 36056.2975 - val_loss: 45079.3758\n",
      "Epoch 27/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 35748.2625 - val_loss: 44683.8897\n",
      "Epoch 28/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 36220.0977 - val_loss: 46708.8979\n",
      "Epoch 29/100\n",
      "1137/1137 [==============================] - 0s 109us/step - loss: 35729.1991 - val_loss: 44926.2810\n",
      "Epoch 30/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 35210.1378 - val_loss: 45022.2143\n",
      "Epoch 31/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 35265.0528 - val_loss: 44608.7009\n",
      "Epoch 32/100\n",
      "1137/1137 [==============================] - 0s 128us/step - loss: 35277.7398 - val_loss: 45359.1107\n",
      "Epoch 33/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 35512.2528 - val_loss: 44439.5752\n",
      "Epoch 34/100\n",
      "1137/1137 [==============================] - 0s 124us/step - loss: 35573.7625 - val_loss: 44410.8242\n",
      "Epoch 35/100\n",
      "1137/1137 [==============================] - 0s 164us/step - loss: 35113.0594 - val_loss: 44422.2079\n",
      "Epoch 36/100\n",
      "1137/1137 [==============================] - 0s 132us/step - loss: 35628.7863 - val_loss: 44442.3882\n",
      "Epoch 37/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 35227.5209 - val_loss: 44675.0332\n",
      "Epoch 38/100\n",
      "1137/1137 [==============================] - 0s 157us/step - loss: 35431.7764 - val_loss: 44226.5475\n",
      "Epoch 39/100\n",
      "1137/1137 [==============================] - 0s 123us/step - loss: 34762.5971 - val_loss: 49088.0038\n",
      "Epoch 40/100\n",
      "1137/1137 [==============================] - 0s 141us/step - loss: 35825.6452 - val_loss: 44326.6555\n",
      "Epoch 41/100\n",
      "1137/1137 [==============================] - 0s 131us/step - loss: 34949.5447 - val_loss: 44425.2525\n",
      "Epoch 42/100\n",
      "1137/1137 [==============================] - 0s 110us/step - loss: 35034.6834 - val_loss: 44271.0721\n",
      "Epoch 43/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 35084.4800 - val_loss: 44255.7341\n",
      "Epoch 44/100\n",
      "1137/1137 [==============================] - 0s 114us/step - loss: 35104.8991 - val_loss: 45037.1536\n",
      "Epoch 45/100\n",
      "1137/1137 [==============================] - 0s 135us/step - loss: 34828.2454 - val_loss: 44833.4448\n",
      "Epoch 46/100\n",
      "1137/1137 [==============================] - 0s 127us/step - loss: 34850.1046 - val_loss: 44239.8232\n",
      "Epoch 47/100\n",
      "1137/1137 [==============================] - 0s 109us/step - loss: 34328.8181 - val_loss: 44358.4718\n",
      "Epoch 48/100\n",
      "1137/1137 [==============================] - 0s 126us/step - loss: 34136.6207 - val_loss: 44199.0003\n",
      "Epoch 49/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 34550.1958 - val_loss: 44087.0802\n",
      "Epoch 50/100\n",
      "1137/1137 [==============================] - 0s 139us/step - loss: 35037.9363 - val_loss: 44029.1228\n",
      "Epoch 51/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 34456.3657 - val_loss: 43947.9525\n",
      "Epoch 52/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 34599.9705 - val_loss: 44962.5532\n",
      "Epoch 53/100\n",
      "1137/1137 [==============================] - 0s 129us/step - loss: 34796.0174 - val_loss: 44103.5835\n",
      "Epoch 54/100\n",
      "1137/1137 [==============================] - 0s 142us/step - loss: 34810.7282 - val_loss: 44535.5652\n",
      "Epoch 55/100\n",
      "1137/1137 [==============================] - 0s 131us/step - loss: 34038.8623 - val_loss: 44163.3649\n",
      "Epoch 56/100\n",
      "1137/1137 [==============================] - 0s 126us/step - loss: 34582.0687 - val_loss: 44318.3351\n",
      "Epoch 57/100\n",
      "1137/1137 [==============================] - 0s 176us/step - loss: 34430.9275 - val_loss: 44065.8519\n",
      "Epoch 58/100\n",
      "1137/1137 [==============================] - 0s 138us/step - loss: 34309.2880 - val_loss: 44048.9875\n",
      "Epoch 59/100\n",
      "1137/1137 [==============================] - 0s 123us/step - loss: 34174.9501 - val_loss: 44286.7885\n",
      "Epoch 60/100\n",
      "1137/1137 [==============================] - 0s 195us/step - loss: 34382.7826 - val_loss: 44026.5434\n",
      "Epoch 61/100\n",
      "1137/1137 [==============================] - 0s 137us/step - loss: 34180.6758 - val_loss: 44927.8573\n",
      "Epoch 62/100\n",
      "1137/1137 [==============================] - 0s 123us/step - loss: 34012.2069 - val_loss: 44889.8419\n",
      "Epoch 63/100\n",
      "1137/1137 [==============================] - 0s 130us/step - loss: 34128.9121 - val_loss: 46422.8104\n",
      "Epoch 64/100\n",
      "1137/1137 [==============================] - 0s 120us/step - loss: 33728.9523 - val_loss: 44646.1000\n",
      "Epoch 65/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 33679.5066 - val_loss: 44219.4811\n",
      "Epoch 66/100\n",
      "1137/1137 [==============================] - 0s 106us/step - loss: 33930.6720 - val_loss: 44566.4508\n",
      "Epoch 67/100\n",
      "1137/1137 [==============================] - 0s 114us/step - loss: 33765.2903 - val_loss: 44212.3260\n",
      "Epoch 68/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 34047.5358 - val_loss: 44250.8552\n",
      "Epoch 69/100\n",
      "1137/1137 [==============================] - 0s 109us/step - loss: 33797.6826 - val_loss: 44212.9666\n",
      "Epoch 70/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 33516.9284 - val_loss: 44288.0770\n",
      "Epoch 71/100\n",
      "1137/1137 [==============================] - 0s 112us/step - loss: 33610.1705 - val_loss: 45364.9488\n",
      "Epoch 72/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 33594.8065 - val_loss: 45719.5998\n",
      "Epoch 73/100\n",
      "1137/1137 [==============================] - 0s 106us/step - loss: 33230.4960 - val_loss: 44848.5401\n",
      "Epoch 74/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 33566.1026 - val_loss: 44150.2931\n",
      "Epoch 75/100\n",
      "1137/1137 [==============================] - 0s 125us/step - loss: 33185.7390 - val_loss: 44130.9541\n",
      "Epoch 76/100\n",
      "1137/1137 [==============================] - 0s 166us/step - loss: 33306.4425 - val_loss: 44173.9915\n",
      "Epoch 77/100\n",
      "1137/1137 [==============================] - 0s 143us/step - loss: 33236.3809 - val_loss: 43982.1238\n",
      "Epoch 78/100\n",
      "1137/1137 [==============================] - 0s 119us/step - loss: 32954.2558 - val_loss: 44232.0163\n",
      "Epoch 79/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 32745.1445 - val_loss: 45848.8608\n",
      "Epoch 80/100\n",
      "1137/1137 [==============================] - 0s 103us/step - loss: 33122.7468 - val_loss: 44264.1495\n",
      "Epoch 81/100\n",
      "1137/1137 [==============================] - 0s 112us/step - loss: 33046.6597 - val_loss: 44362.6309\n",
      "Epoch 82/100\n",
      "1137/1137 [==============================] - 0s 117us/step - loss: 32959.4454 - val_loss: 44365.5655\n",
      "Epoch 83/100\n",
      "1137/1137 [==============================] - 0s 155us/step - loss: 32826.1044 - val_loss: 44135.5784\n",
      "Epoch 84/100\n",
      "1137/1137 [==============================] - 0s 107us/step - loss: 32849.5957 - val_loss: 45422.7765\n",
      "Epoch 85/100\n",
      "1137/1137 [==============================] - 0s 110us/step - loss: 32944.2929 - val_loss: 44223.9977\n",
      "Epoch 86/100\n",
      "1137/1137 [==============================] - 0s 112us/step - loss: 32910.8755 - val_loss: 44629.7086\n",
      "Epoch 87/100\n",
      "1137/1137 [==============================] - 0s 116us/step - loss: 32465.4973 - val_loss: 44242.2784\n",
      "Epoch 88/100\n",
      "1137/1137 [==============================] - 0s 111us/step - loss: 32618.2089 - val_loss: 44465.9635\n",
      "Epoch 89/100\n",
      "1137/1137 [==============================] - 0s 115us/step - loss: 32743.9154 - val_loss: 44362.2080\n",
      "Epoch 90/100\n",
      "1137/1137 [==============================] - 0s 121us/step - loss: 32503.0046 - val_loss: 45681.7522\n",
      "Epoch 91/100\n",
      "1137/1137 [==============================] - 0s 113us/step - loss: 32533.0042 - val_loss: 44660.1032\n",
      "Epoch 92/100\n",
      "1137/1137 [==============================] - 0s 110us/step - loss: 32378.7772 - val_loss: 44331.0009\n",
      "Epoch 93/100\n",
      "1137/1137 [==============================] - 0s 114us/step - loss: 32731.7108 - val_loss: 44312.9624\n",
      "Epoch 94/100\n",
      "1137/1137 [==============================] - 0s 117us/step - loss: 32055.8805 - val_loss: 45320.2611\n",
      "Epoch 95/100\n",
      "1137/1137 [==============================] - 0s 110us/step - loss: 32195.7390 - val_loss: 44419.5332\n",
      "Epoch 96/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 32086.0580 - val_loss: 44432.3395\n",
      "Epoch 97/100\n",
      "1137/1137 [==============================] - 0s 107us/step - loss: 32440.5528 - val_loss: 44567.2381\n",
      "Epoch 98/100\n",
      "1137/1137 [==============================] - 0s 113us/step - loss: 32552.0489 - val_loss: 44422.6866\n",
      "Epoch 99/100\n",
      "1137/1137 [==============================] - 0s 118us/step - loss: 31975.3086 - val_loss: 44305.7735\n",
      "Epoch 100/100\n",
      "1137/1137 [==============================] - 0s 116us/step - loss: 32348.3550 - val_loss: 44734.3469\n"
     ]
    }
   ],
   "source": [
    "model_build_1 = model_build_dl_1(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = model_build_1.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Successful file created : forth_DL'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_submission_file( y_pred_1, filename = \"forth_DL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build_dl_2(X_train_val, y_train_val):\n",
    "    # Fitting the ANN to the Training set\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape = (X_train.shape[1], ), activation = 'relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    \n",
    "#     model_history = model.fit(X_train_val, y_train_val, epochs=200, batch_size=16, validation_split = 0.001, verbose=0)\n",
    "    \n",
    "    model_history_val = model.fit(X_train_val, y_train_val, epochs=1000, batch_size=16, validation_split = 0.001)\n",
    "    \n",
    "    \n",
    "    #     model_history=model.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)\n",
    "    return model, model_history_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1420 samples, validate on 2 samples\n",
      "Epoch 1/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 2/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 3/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 4/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 5/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 6/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 7/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 8/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 9/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 10/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 11/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 12/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 13/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 14/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 15/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 16/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 17/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 18/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 19/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 20/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 21/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 22/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 23/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 24/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 25/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 26/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 27/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 28/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 29/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 30/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 31/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 32/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 33/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 34/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 35/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 36/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 37/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 38/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 39/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 40/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073100.0789 - val_loss: 20977883136.0000\n",
      "Epoch 41/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 42/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 43/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 44/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 45/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 46/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n",
      "Epoch 47/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 48/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 49/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 50/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 51/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073077.0028 - val_loss: 20977883136.0000\n",
      "Epoch 52/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 53/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 54/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 55/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 56/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 57/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073861.5887 - val_loss: 20977883136.0000\n",
      "Epoch 58/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 59/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 60/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 61/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 62/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 63/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 64/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 65/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 67/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 68/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777072990.4676 - val_loss: 20977883136.0000\n",
      "Epoch 69/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 70/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073751.9775 - val_loss: 20977883136.0000\n",
      "Epoch 71/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 72/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 73/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 74/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 75/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 76/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 77/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 78/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 79/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073861.5887 - val_loss: 20977883136.0000\n",
      "Epoch 80/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 81/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 82/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 83/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 84/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 85/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 86/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 87/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 88/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 89/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 90/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 91/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39461884660.869 - 0s 66us/step - loss: 39777073607.7521 - val_loss: 20977883136.0000\n",
      "Epoch 92/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 93/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 94/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 95/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 96/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073671.2113 - val_loss: 20977883136.0000\n",
      "Epoch 97/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 98/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 99/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 100/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 101/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 102/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073111.6169 - val_loss: 20977883136.0000\n",
      "Epoch 103/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073267.3803 - val_loss: 20977883136.0000\n",
      "Epoch 104/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 105/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 106/1000\n",
      "1420/1420 [==============================] - 0s 105us/step - loss: 39777073169.3070 - val_loss: 20977883136.0000\n",
      "Epoch 107/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 108/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 109/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 110/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 111/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 112/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073169.3070 - val_loss: 20977883136.0000\n",
      "Epoch 113/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 114/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 115/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 116/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 117/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073111.6169 - val_loss: 20977883136.0000\n",
      "Epoch 118/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 119/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 120/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 121/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 122/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 123/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 124/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 125/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 126/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073169.3070 - val_loss: 20977883136.0000\n",
      "Epoch 127/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 128/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 129/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 130/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 131/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 132/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073613.5211 - val_loss: 20977883136.0000\n",
      "Epoch 133/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 134/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 135/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 136/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 137/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 138/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073850.0507 - val_loss: 20977883136.0000\n",
      "Epoch 139/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 140/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 141/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 142/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 143/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 144/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 41142772352.000 - 0s 68us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 145/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 146/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 147/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 148/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 149/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n",
      "Epoch 150/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 151/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 152/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 153/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 154/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073705.8254 - val_loss: 20977883136.0000\n",
      "Epoch 155/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 156/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 157/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 158/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 159/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073221.2282 - val_loss: 20977883136.0000\n",
      "Epoch 160/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 161/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 162/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 163/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 164/1000\n",
      "1420/1420 [==============================] - 0s 114us/step - loss: 39777073088.5408 - val_loss: 20977883136.0000\n",
      "Epoch 165/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 166/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 167/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 168/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073232.7662 - val_loss: 20977883136.0000\n",
      "Epoch 169/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073163.5380 - val_loss: 20977883136.0000\n",
      "Epoch 170/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 171/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 172/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 173/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 174/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 175/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 176/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073873.1268 - val_loss: 20977883136.0000\n",
      "Epoch 177/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 178/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 179/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 180/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 181/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073821.2056 - val_loss: 20977883136.0000\n",
      "Epoch 182/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 183/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 184/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 185/1000\n",
      "1420/1420 [==============================] - 0s 90us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 186/1000\n",
      "1420/1420 [==============================] - 0s 105us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 187/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073625.0592 - val_loss: 20977883136.0000\n",
      "Epoch 188/1000\n",
      "1420/1420 [==============================] - 0s 124us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 189/1000\n",
      "1420/1420 [==============================] - 0s 128us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 190/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 191/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 192/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 193/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 107us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 195/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 196/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 197/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 198/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 199/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 200/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777072990.4676 - val_loss: 20977883136.0000\n",
      "Epoch 201/1000\n",
      "1420/1420 [==============================] - 0s 58us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 202/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 203/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 204/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 205/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 206/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 207/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 208/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073694.2873 - val_loss: 20977883136.0000\n",
      "Epoch 209/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 210/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n",
      "Epoch 211/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073942.3549 - val_loss: 20977883136.0000\n",
      "Epoch 212/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 213/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073861.5887 - val_loss: 20977883136.0000\n",
      "Epoch 214/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 215/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 216/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 217/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 218/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 219/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 220/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 221/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 222/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 223/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 224/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 225/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 226/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 227/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 228/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 229/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 230/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 231/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 232/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 233/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 234/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 235/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 236/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 237/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 238/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 239/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 240/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073140.4620 - val_loss: 20977883136.0000\n",
      "Epoch 241/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 242/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073780.8225 - val_loss: 20977883136.0000\n",
      "Epoch 243/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 244/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n",
      "Epoch 245/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 246/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 247/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 248/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 249/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 250/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073659.6732 - val_loss: 20977883136.0000\n",
      "Epoch 251/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 252/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 253/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 254/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 255/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073694.2873 - val_loss: 20977883136.0000\n",
      "Epoch 256/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 257/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 258/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073590.4451 - val_loss: 20977883136.0000\n",
      "Epoch 259/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 260/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073053.9268 - val_loss: 20977883136.0000\n",
      "Epoch 261/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073578.9070 - val_loss: 20977883136.0000\n",
      "Epoch 262/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 263/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073803.8986 - val_loss: 20977883136.0000\n",
      "Epoch 264/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 265/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 266/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073163.5380 - val_loss: 20977883136.0000\n",
      "Epoch 267/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 268/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 269/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 270/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777072973.1606 - val_loss: 20977883136.0000\n",
      "Epoch 271/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 272/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 273/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073117.3859 - val_loss: 20977883136.0000\n",
      "Epoch 274/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073100.0789 - val_loss: 20977883136.0000\n",
      "Epoch 275/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073826.9746 - val_loss: 20977883136.0000\n",
      "Epoch 276/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 277/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 278/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 279/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 280/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 281/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 282/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 283/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 284/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 285/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 286/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 287/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 288/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 289/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 290/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39404496329.531 - 0s 67us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 291/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 292/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 293/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 294/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 295/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 296/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 297/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 298/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 299/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 300/1000\n",
      "1420/1420 [==============================] - 0s 59us/step - loss: 39777073625.0592 - val_loss: 20977883136.0000\n",
      "Epoch 301/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 302/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 303/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 304/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 305/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 306/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 307/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 308/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073746.2085 - val_loss: 20977883136.0000\n",
      "Epoch 309/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 310/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 311/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 312/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 313/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 314/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 315/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 316/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 317/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 318/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 319/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 320/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 321/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 323/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 324/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 325/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 326/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 327/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 328/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 329/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 330/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 331/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 332/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073775.0535 - val_loss: 20977883136.0000\n",
      "Epoch 333/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 334/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 335/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 336/1000\n",
      "1420/1420 [==============================] - 0s 112us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 337/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 338/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 339/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 340/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 341/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 342/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 343/1000\n",
      "1420/1420 [==============================] - 0s 59us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 344/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 345/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 346/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 347/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 348/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 349/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 350/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 38890124928.000 - 0s 68us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 351/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 352/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073746.2085 - val_loss: 20977883136.0000\n",
      "Epoch 353/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 354/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 355/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 356/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 357/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 358/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 359/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 360/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 361/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 362/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 363/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 364/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n",
      "Epoch 365/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073267.3803 - val_loss: 20977883136.0000\n",
      "Epoch 366/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 367/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073746.2085 - val_loss: 20977883136.0000\n",
      "Epoch 368/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 369/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073290.4563 - val_loss: 20977883136.0000\n",
      "Epoch 370/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 371/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073578.9070 - val_loss: 20977883136.0000\n",
      "Epoch 372/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 373/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 374/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 375/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 376/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 377/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 378/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 379/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073740.4394 - val_loss: 20977883136.0000\n",
      "Epoch 380/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 381/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 382/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 383/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 384/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 385/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 386/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 387/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 388/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 389/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 390/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 391/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 392/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 393/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 394/1000\n",
      "1420/1420 [==============================] - 0s 112us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 395/1000\n",
      "1420/1420 [==============================] - 0s 114us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 396/1000\n",
      "1420/1420 [==============================] - 0s 114us/step - loss: 39777073105.8479 - val_loss: 20977883136.0000\n",
      "Epoch 397/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073077.0028 - val_loss: 20977883136.0000\n",
      "Epoch 398/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 399/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 400/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 401/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073221.2282 - val_loss: 20977883136.0000\n",
      "Epoch 402/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 403/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 404/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 405/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 406/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 407/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 408/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 409/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 410/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073613.5211 - val_loss: 20977883136.0000\n",
      "Epoch 411/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 412/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 413/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 414/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 415/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 416/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 417/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 418/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 419/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 420/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 421/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 422/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073792.3606 - val_loss: 20977883136.0000\n",
      "Epoch 423/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 424/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 425/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073192.3831 - val_loss: 20977883136.0000\n",
      "Epoch 426/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 427/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 428/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073740.4394 - val_loss: 20977883136.0000\n",
      "Epoch 429/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 430/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 431/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 432/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073301.9944 - val_loss: 20977883136.0000\n",
      "Epoch 433/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 434/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 435/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 436/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 437/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 438/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 439/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 440/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 441/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 442/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 443/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 444/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073734.6704 - val_loss: 20977883136.0000\n",
      "Epoch 445/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 446/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 447/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 448/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 449/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 450/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 90us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 451/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 452/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 453/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073815.4366 - val_loss: 20977883136.0000\n",
      "Epoch 454/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 455/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 456/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777072996.2366 - val_loss: 20977883136.0000\n",
      "Epoch 457/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 458/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 459/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 460/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 461/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 462/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073186.6141 - val_loss: 20977883136.0000\n",
      "Epoch 463/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 464/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 465/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 466/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 467/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 468/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 469/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 470/1000\n",
      "1420/1420 [==============================] - 0s 102us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 471/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 472/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n",
      "Epoch 473/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 474/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 475/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 476/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 477/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073255.8423 - val_loss: 20977883136.0000\n",
      "Epoch 478/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 479/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 480/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 481/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 482/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 483/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 484/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 485/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 486/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 487/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 488/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 489/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 490/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073221.2282 - val_loss: 20977883136.0000\n",
      "Epoch 491/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073717.3634 - val_loss: 20977883136.0000\n",
      "Epoch 492/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 493/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 494/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 495/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 496/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 497/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 498/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 499/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39604551013.783 - 0s 79us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 500/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 501/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 502/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 503/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 504/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 505/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073740.4394 - val_loss: 20977883136.0000\n",
      "Epoch 506/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 507/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 508/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 509/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 510/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 511/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 512/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 513/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 514/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 515/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 516/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 517/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 518/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 519/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 520/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073694.2873 - val_loss: 20977883136.0000\n",
      "Epoch 521/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 522/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073019.3127 - val_loss: 20977883136.0000\n",
      "Epoch 523/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 524/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 525/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 526/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073221.2282 - val_loss: 20977883136.0000\n",
      "Epoch 527/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 528/1000\n",
      "1420/1420 [==============================] - 0s 90us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 529/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 530/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 531/1000\n",
      "1420/1420 [==============================] - 0s 99us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 532/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 533/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 534/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 535/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 536/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 537/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 538/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073671.2113 - val_loss: 20977883136.0000\n",
      "Epoch 539/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073838.5127 - val_loss: 20977883136.0000\n",
      "Epoch 540/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 541/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073152.0000 - val_loss: 20977883136.0000\n",
      "Epoch 542/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073746.2085 - val_loss: 20977883136.0000\n",
      "Epoch 543/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 544/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 545/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 546/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 547/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 548/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 549/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 550/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 551/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 552/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 553/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 554/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 555/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 556/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 557/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073065.4648 - val_loss: 20977883136.0000\n",
      "Epoch 558/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 559/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 560/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 561/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 562/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 563/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 564/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073157.7690 - val_loss: 20977883136.0000\n",
      "Epoch 565/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 566/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073325.0704 - val_loss: 20977883136.0000\n",
      "Epoch 567/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 568/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 569/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 570/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 571/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 572/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073163.5380 - val_loss: 20977883136.0000\n",
      "Epoch 573/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 574/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 575/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073192.3831 - val_loss: 20977883136.0000\n",
      "Epoch 576/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 577/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 578/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 579/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 580/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 581/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 582/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073105.8479 - val_loss: 20977883136.0000\n",
      "Epoch 583/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 584/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 585/1000\n",
      "1420/1420 [==============================] - 0s 105us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 586/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 587/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 588/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073613.5211 - val_loss: 20977883136.0000\n",
      "Epoch 589/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 590/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 591/1000\n",
      "1420/1420 [==============================] - 0s 117us/step - loss: 39777073244.3042 - val_loss: 20977883136.0000\n",
      "Epoch 592/1000\n",
      "1420/1420 [==============================] - 0s 136us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 593/1000\n",
      "1420/1420 [==============================] - 0s 134us/step - loss: 39777073169.3070 - val_loss: 20977883136.0000\n",
      "Epoch 594/1000\n",
      "1420/1420 [==============================] - 0s 102us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 595/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 596/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 597/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 598/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073428.9127 - val_loss: 20977883136.0000\n",
      "Epoch 599/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073682.7493 - val_loss: 20977883136.0000\n",
      "Epoch 600/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 601/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 602/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 603/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 604/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 605/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 606/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073613.5211 - val_loss: 20977883136.0000\n",
      "Epoch 607/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 608/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 609/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 610/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39483520105.025 - 0s 84us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 611/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 612/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 613/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 614/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 615/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 616/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 617/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 618/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 619/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 620/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073653.9042 - val_loss: 20977883136.0000\n",
      "Epoch 621/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 622/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 623/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 624/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 625/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 626/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 627/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 628/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 629/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073192.3831 - val_loss: 20977883136.0000\n",
      "Epoch 630/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 631/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 632/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 633/1000\n",
      "1420/1420 [==============================] - 0s 118us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 634/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 635/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 636/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 637/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 638/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 639/1000\n",
      "1420/1420 [==============================] - 0s 130us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 640/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 641/1000\n",
      "1420/1420 [==============================] - 0s 110us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 642/1000\n",
      "1420/1420 [==============================] - 0s 139us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 643/1000\n",
      "1420/1420 [==============================] - 0s 130us/step - loss: 39777073053.9268 - val_loss: 20977883136.0000\n",
      "Epoch 644/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 645/1000\n",
      "1420/1420 [==============================] - 0s 119us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 646/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 647/1000\n",
      "1420/1420 [==============================] - 0s 159us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 648/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 649/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 650/1000\n",
      "1420/1420 [==============================] - 0s 120us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 651/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 652/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073278.9183 - val_loss: 20977883136.0000\n",
      "Epoch 653/1000\n",
      "1420/1420 [==============================] - 0s 90us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 654/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073873.1268 - val_loss: 20977883136.0000\n",
      "Epoch 655/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 656/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 657/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 658/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073838.5127 - val_loss: 20977883136.0000\n",
      "Epoch 659/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073607.7521 - val_loss: 20977883136.0000\n",
      "Epoch 660/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 661/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073209.6901 - val_loss: 20977883136.0000\n",
      "Epoch 662/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 663/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073578.9070 - val_loss: 20977883136.0000\n",
      "Epoch 664/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 665/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 666/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 667/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 668/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 669/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 670/1000\n",
      "1420/1420 [==============================] - 0s 59us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 671/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 672/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073780.8225 - val_loss: 20977883136.0000\n",
      "Epoch 673/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 674/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 675/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 676/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 677/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39410014129.230 - 0s 66us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 678/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073088.5408 - val_loss: 20977883136.0000\n",
      "Epoch 679/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 680/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 681/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 682/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 683/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 684/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 685/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 686/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 687/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 688/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 689/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 690/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40639632856.615 - 0s 62us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 691/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 692/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 693/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073244.3042 - val_loss: 20977883136.0000\n",
      "Epoch 694/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073244.3042 - val_loss: 20977883136.0000\n",
      "Epoch 695/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 696/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 697/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073850.0507 - val_loss: 20977883136.0000\n",
      "Epoch 698/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 699/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 700/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40259704477.538 - 0s 63us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 701/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073146.2310 - val_loss: 20977883136.0000\n",
      "Epoch 702/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 703/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 704/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 705/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 706/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073682.7493 - val_loss: 20977883136.0000\n",
      "Epoch 707/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 708/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 709/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 710/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 711/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 712/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 713/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 714/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 715/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 716/1000\n",
      "1420/1420 [==============================] - 0s 133us/step - loss: 39777073382.7606 - val_loss: 20977883136.0000\n",
      "Epoch 717/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 718/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 719/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 720/1000\n",
      "1420/1420 [==============================] - 0s 115us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 721/1000\n",
      "1420/1420 [==============================] - 0s 115us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 722/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 723/1000\n",
      "1420/1420 [==============================] - 0s 131us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 724/1000\n",
      "1420/1420 [==============================] - 0s 100us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 725/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073775.0535 - val_loss: 20977883136.0000\n",
      "Epoch 726/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 727/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073192.3831 - val_loss: 20977883136.0000\n",
      "Epoch 728/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073671.2113 - val_loss: 20977883136.0000\n",
      "Epoch 729/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 730/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 731/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 732/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 733/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 734/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073676.9803 - val_loss: 20977883136.0000\n",
      "Epoch 735/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 736/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073267.3803 - val_loss: 20977883136.0000\n",
      "Epoch 737/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 738/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 739/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 740/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40081240309.760 - 0s 64us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 741/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 742/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073088.5408 - val_loss: 20977883136.0000\n",
      "Epoch 743/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 744/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 745/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 746/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 747/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 748/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 749/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 750/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 751/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 752/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073728.9014 - val_loss: 20977883136.0000\n",
      "Epoch 753/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 754/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 755/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 756/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 757/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 758/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 759/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 760/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 761/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 762/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 763/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 764/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073780.8225 - val_loss: 20977883136.0000\n",
      "Epoch 765/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 766/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 767/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 768/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 769/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 770/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073417.3746 - val_loss: 20977883136.0000\n",
      "Epoch 771/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 772/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 773/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073180.8451 - val_loss: 20977883136.0000\n",
      "Epoch 774/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073665.4423 - val_loss: 20977883136.0000\n",
      "Epoch 775/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 776/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 777/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 778/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 779/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 780/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073186.6141 - val_loss: 20977883136.0000\n",
      "Epoch 781/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 782/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 783/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 784/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 785/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 786/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 787/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 788/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073105.8479 - val_loss: 20977883136.0000\n",
      "Epoch 789/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 790/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073544.2930 - val_loss: 20977883136.0000\n",
      "Epoch 791/1000\n",
      "1420/1420 [==============================] - 0s 91us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 792/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 793/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 794/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073550.0620 - val_loss: 20977883136.0000\n",
      "Epoch 795/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 796/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073688.5183 - val_loss: 20977883136.0000\n",
      "Epoch 797/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 798/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 38888196411.076 - 0s 63us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 799/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 800/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 801/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 802/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 803/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 804/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 805/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073590.4451 - val_loss: 20977883136.0000\n",
      "Epoch 806/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 807/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073578.9070 - val_loss: 20977883136.0000\n",
      "Epoch 808/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 809/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073573.1380 - val_loss: 20977883136.0000\n",
      "Epoch 810/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 811/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 812/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 813/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 814/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073287.5718 - val_loss: 20977883136.0000\n",
      "Epoch 815/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 816/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39968970872.470 - 0s 65us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 817/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 818/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 819/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 820/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 821/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39203724051.692 - 0s 65us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 822/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 823/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073100.0789 - val_loss: 20977883136.0000\n",
      "Epoch 824/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 825/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 826/1000\n",
      "1420/1420 [==============================] - 0s 68us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 827/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 828/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073815.4366 - val_loss: 20977883136.0000\n",
      "Epoch 829/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 830/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 831/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 832/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 833/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073803.8986 - val_loss: 20977883136.0000\n",
      "Epoch 835/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40187343169.254 - 0s 63us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 836/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073873.1268 - val_loss: 20977883136.0000\n",
      "Epoch 837/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073601.9831 - val_loss: 20977883136.0000\n",
      "Epoch 838/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073371.2225 - val_loss: 20977883136.0000\n",
      "Epoch 839/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 840/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 841/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 842/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 843/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 38950301985.811 - 0s 65us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 844/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 845/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39720669962.240 - 0s 68us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 846/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 847/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073244.3042 - val_loss: 20977883136.0000\n",
      "Epoch 848/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073584.6761 - val_loss: 20977883136.0000\n",
      "Epoch 849/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 850/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073451.9887 - val_loss: 20977883136.0000\n",
      "Epoch 851/1000\n",
      "1420/1420 [==============================] - 0s 73us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 852/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 853/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 854/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 855/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073209.6901 - val_loss: 20977883136.0000\n",
      "Epoch 856/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073757.7465 - val_loss: 20977883136.0000\n",
      "Epoch 857/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073019.3127 - val_loss: 20977883136.0000\n",
      "Epoch 858/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073238.5352 - val_loss: 20977883136.0000\n",
      "Epoch 859/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073405.8366 - val_loss: 20977883136.0000\n",
      "Epoch 860/1000\n",
      "1420/1420 [==============================] - 0s 69us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 861/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39902246144.000 - 0s 67us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 862/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 863/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 864/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073100.0789 - val_loss: 20977883136.0000\n",
      "Epoch 865/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073567.3690 - val_loss: 20977883136.0000\n",
      "Epoch 866/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 867/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 868/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 869/1000\n",
      "1420/1420 [==============================] - 0s 66us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 870/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 871/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073515.4479 - val_loss: 20977883136.0000\n",
      "Epoch 872/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073348.1465 - val_loss: 20977883136.0000\n",
      "Epoch 873/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 874/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073521.2169 - val_loss: 20977883136.0000\n",
      "Epoch 875/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 876/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073325.0704 - val_loss: 20977883136.0000\n",
      "Epoch 877/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073053.9268 - val_loss: 20977883136.0000\n",
      "Epoch 878/1000\n",
      "1420/1420 [==============================] - 0s 60us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 879/1000\n",
      "1420/1420 [==============================] - 0s 61us/step - loss: 39777073723.1324 - val_loss: 20977883136.0000\n",
      "Epoch 880/1000\n",
      "1420/1420 [==============================] - 0s 67us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 881/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073307.7634 - val_loss: 20977883136.0000\n",
      "Epoch 882/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 883/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 884/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073330.8394 - val_loss: 20977883136.0000\n",
      "Epoch 885/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 886/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 887/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 888/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 889/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 890/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073313.5324 - val_loss: 20977883136.0000\n",
      "Epoch 891/1000\n",
      "1420/1420 [==============================] - 0s 63us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 892/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 893/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 894/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 895/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 896/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 897/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073498.1408 - val_loss: 20977883136.0000\n",
      "Epoch 898/1000\n",
      "1420/1420 [==============================] - 0s 64us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 899/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 40553613430.153 - 0s 62us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 900/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 901/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 902/1000\n",
      "1420/1420 [==============================] - 0s 62us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 903/1000\n",
      "1420/1420 [==============================] - 0s 65us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 904/1000\n",
      "1420/1420 [==============================] - 0s 75us/step - loss: 39777073059.6958 - val_loss: 20977883136.0000\n",
      "Epoch 905/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073555.8310 - val_loss: 20977883136.0000\n",
      "Epoch 906/1000\n",
      "1420/1420 [==============================] - 0s 77us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 907/1000\n",
      "1420/1420 [==============================] - 0s 76us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 908/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073567.3690 - val_loss: 20977883136.0000\n",
      "Epoch 909/1000\n",
      "1420/1420 [==============================] - 0s 71us/step - loss: 39777073226.9972 - val_loss: 20977883136.0000\n",
      "Epoch 910/1000\n",
      "1420/1420 [==============================] - 0s 70us/step - loss: 39777073423.1437 - val_loss: 20977883136.0000\n",
      "Epoch 911/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 912/1000\n",
      "1420/1420 [==============================] - 0s 72us/step - loss: 39777073503.9099 - val_loss: 20977883136.0000\n",
      "Epoch 913/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073434.6817 - val_loss: 20977883136.0000\n",
      "Epoch 914/1000\n",
      "1420/1420 [==============================] - 0s 164us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 915/1000\n",
      "1420/1420 [==============================] - 0s 123us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 916/1000\n",
      "1420/1420 [==============================] - 0s 110us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 917/1000\n",
      "1420/1420 [==============================] - 0s 105us/step - loss: 39777073042.3887 - val_loss: 20977883136.0000\n",
      "Epoch 918/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 919/1000\n",
      "1420/1420 [==============================] - 0s 119us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 920/1000\n",
      "1420/1420 [==============================] - 0s 122us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 921/1000\n",
      "1420/1420 [==============================] - 0s 131us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 922/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073907.7408 - val_loss: 20977883136.0000\n",
      "Epoch 923/1000\n",
      "1420/1420 [==============================] - 0s 126us/step - loss: 39777073700.0563 - val_loss: 20977883136.0000\n",
      "Epoch 924/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073509.6789 - val_loss: 20977883136.0000\n",
      "Epoch 925/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073319.3014 - val_loss: 20977883136.0000\n",
      "Epoch 926/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073261.6113 - val_loss: 20977883136.0000\n",
      "Epoch 927/1000\n",
      "1420/1420 [==============================] - 0s 108us/step - loss: 39777073048.1577 - val_loss: 20977883136.0000\n",
      "Epoch 928/1000\n",
      "1420/1420 [==============================] - 0s 164us/step - loss: 39777073296.2253 - val_loss: 20977883136.0000\n",
      "Epoch 929/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073561.6000 - val_loss: 20977883136.0000\n",
      "Epoch 930/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073111.6169 - val_loss: 20977883136.0000\n",
      "Epoch 931/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 932/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 933/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073532.7549 - val_loss: 20977883136.0000\n",
      "Epoch 934/1000\n",
      "1420/1420 [==============================] - 0s 106us/step - loss: 39777073440.4507 - val_loss: 20977883136.0000\n",
      "Epoch 935/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 936/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 937/1000\n",
      "1420/1420 [==============================] - 0s 106us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 938/1000\n",
      "1420/1420 [==============================] - 0s 110us/step - loss: 39777073203.9211 - val_loss: 20977883136.0000\n",
      "Epoch 939/1000\n",
      "1420/1420 [==============================] - 0s 113us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 940/1000\n",
      "1420/1420 [==============================] - 0s 116us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 941/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073284.6873 - val_loss: 20977883136.0000\n",
      "Epoch 942/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073648.1352 - val_loss: 20977883136.0000\n",
      "Epoch 943/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073457.7577 - val_loss: 20977883136.0000\n",
      "Epoch 944/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073336.6085 - val_loss: 20977883136.0000\n",
      "Epoch 945/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073134.6930 - val_loss: 20977883136.0000\n",
      "Epoch 946/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 947/1000\n",
      "1420/1420 [==============================] - 0s 93us/step - loss: 39777073480.8338 - val_loss: 20977883136.0000\n",
      "Epoch 948/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 949/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073694.2873 - val_loss: 20977883136.0000\n",
      "Epoch 950/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073446.2197 - val_loss: 20977883136.0000\n",
      "Epoch 951/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073498.1408 - val_loss: 20977883136.0000\n",
      "Epoch 952/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 953/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 954/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 955/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073642.3662 - val_loss: 20977883136.0000\n",
      "Epoch 956/1000\n",
      "1420/1420 [==============================] - 0s 80us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 957/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073201.0366 - val_loss: 20977883136.0000\n",
      "Epoch 958/1000\n",
      "1420/1420 [==============================] - 0s 87us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 959/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073388.5296 - val_loss: 20977883136.0000\n",
      "Epoch 960/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073636.5972 - val_loss: 20977883136.0000\n",
      "Epoch 962/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 963/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 964/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073469.2958 - val_loss: 20977883136.0000\n",
      "Epoch 965/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073792.3606 - val_loss: 20977883136.0000\n",
      "Epoch 966/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073394.2986 - val_loss: 20977883136.0000\n",
      "Epoch 967/1000\n",
      "1420/1420 [==============================] - 0s 88us/step - loss: 39777073826.9746 - val_loss: 20977883136.0000\n",
      "Epoch 968/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39931749101.268 - 0s 81us/step - loss: 39777073400.0676 - val_loss: 20977883136.0000\n",
      "Epoch 969/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073273.1493 - val_loss: 20977883136.0000\n",
      "Epoch 970/1000\n",
      "1420/1420 [==============================] - 0s 92us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 971/1000\n",
      "1420/1420 [==============================] - 0s 89us/step - loss: 39777073538.5239 - val_loss: 20977883136.0000\n",
      "Epoch 972/1000\n",
      "1420/1420 [==============================] - 0s 106us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 973/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073596.2141 - val_loss: 20977883136.0000\n",
      "Epoch 974/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073267.3803 - val_loss: 20977883136.0000\n",
      "Epoch 975/1000\n",
      "1420/1420 [==============================] - 0s 103us/step - loss: 39777073486.6028 - val_loss: 20977883136.0000\n",
      "Epoch 976/1000\n",
      "1420/1420 [==============================] - 0s 96us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 977/1000\n",
      "1420/1420 [==============================] - 0s 114us/step - loss: 39777073365.4535 - val_loss: 20977883136.0000\n",
      "Epoch 978/1000\n",
      "1420/1420 [==============================] - 0s 95us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n",
      "Epoch 979/1000\n",
      "1420/1420 [==============================] - 0s 104us/step - loss: 39777073492.3718 - val_loss: 20977883136.0000\n",
      "Epoch 980/1000\n",
      "1420/1420 [==============================] - 0s 101us/step - loss: 39777073526.9859 - val_loss: 20977883136.0000\n",
      "Epoch 981/1000\n",
      "1420/1420 [==============================] - 0s 98us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 982/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073215.4592 - val_loss: 20977883136.0000\n",
      "Epoch 983/1000\n",
      "1420/1420 [==============================] - 0s 97us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 984/1000\n",
      "1420/1420 [==============================] - 0s 99us/step - loss: 39777073803.8986 - val_loss: 20977883136.0000\n",
      "Epoch 985/1000\n",
      "1420/1420 [==============================] - 0s 94us/step - loss: 39777073769.2845 - val_loss: 20977883136.0000\n",
      "Epoch 986/1000\n",
      "1420/1420 [==============================] - 0s 85us/step - loss: 39777073411.6056 - val_loss: 20977883136.0000\n",
      "Epoch 987/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073376.9915 - val_loss: 20977883136.0000\n",
      "Epoch 988/1000\n",
      "1420/1420 [==============================] - 0s 84us/step - loss: 39777073711.5944 - val_loss: 20977883136.0000\n",
      "Epoch 989/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073463.5268 - val_loss: 20977883136.0000\n",
      "Epoch 990/1000\n",
      "1420/1420 [==============================] - 0s 82us/step - loss: 39777073353.9155 - val_loss: 20977883136.0000\n",
      "Epoch 991/1000\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 39727150345.481 - 0s 81us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 992/1000\n",
      "1420/1420 [==============================] - 0s 78us/step - loss: 39777073198.1521 - val_loss: 20977883136.0000\n",
      "Epoch 993/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073342.3775 - val_loss: 20977883136.0000\n",
      "Epoch 994/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073359.6845 - val_loss: 20977883136.0000\n",
      "Epoch 995/1000\n",
      "1420/1420 [==============================] - 0s 79us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 996/1000\n",
      "1420/1420 [==============================] - 0s 74us/step - loss: 39777073619.2901 - val_loss: 20977883136.0000\n",
      "Epoch 997/1000\n",
      "1420/1420 [==============================] - 0s 81us/step - loss: 39777073630.8282 - val_loss: 20977883136.0000\n",
      "Epoch 998/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073475.0648 - val_loss: 20977883136.0000\n",
      "Epoch 999/1000\n",
      "1420/1420 [==============================] - 0s 86us/step - loss: 39777073250.0732 - val_loss: 20977883136.0000\n",
      "Epoch 1000/1000\n",
      "1420/1420 [==============================] - 0s 83us/step - loss: 39777073123.1549 - val_loss: 20977883136.0000\n"
     ]
    }
   ],
   "source": [
    "model_build_2, model_history = model_build_dl_2(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = model_build_2.predict(df_Test)\n",
    "create_submission_file( y_pred_2, filename = \"forth_DL_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 128)               22400     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 55,681\n",
      "Trainable params: 55,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_build_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the training data: 39777073123.15493\n"
     ]
    }
   ],
   "source": [
    "print('MSE of the training data: {}' .format(model_history.history['loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29032002198>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'][10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of training data: 39750633017.2609\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_2 = model_build_2.predict(X_train)\n",
    "# print('MSE of training data: {}'.format(mean_squared_error(y_train, y_train_pred_2)))\n",
    "\n",
    "\n",
    "#or\n",
    "y_train_reshape = np.array(y_train).reshape(-1,1)\n",
    "print('MSE of training data: {}'.format(mean_squared_error(y_train_reshape, y_train_pred_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates our Keras model\n",
    "def create_model(optimizer= 'adam' , activation= 'relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(336,), activation=activation))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[\"accuracy\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create a model as a sklearn estimator\n",
    "#     model = KerasClassifier(build_fn=model, epochs=6, batch_size=16, verbose = 0)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model as a sklearn estimator\n",
    "model_hyperparameter = KerasClassifier(build_fn=create_model, epochs=6, batch_size=16, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-7a2e041affdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m                        cv = 10)\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mrandom_search_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# random_search = RandomizedSearchCV(model_hyperparameter, param_distributions=params, cv=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         if (losses.is_categorical_crossentropy(self.model.loss) and\n\u001b[0m\u001b[0;32m    145\u001b[0m                 len(y.shape) != 2):\n\u001b[0;32m    146\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define a series of parameters\n",
    "params = dict(optimizer=['sgd','adam'],batch_size=[16, 32], activation=['relu','tanh', 'sigmoid', 'softmax'])\n",
    "\n",
    "# Create a random search cv object and fit it to the data\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model_hyperparameter,\n",
    "                       param_grid = params,\n",
    "                       scoring = 'accuracy',\n",
    "                       cv = 10)\n",
    "\n",
    "random_search_results = grid_search.fit(X_train, y_train, verbose=0)\n",
    "\n",
    "# random_search = RandomizedSearchCV(model_hyperparameter, param_distributions=params, cv=5)\n",
    "# random_search_results = random_search.fit(X_train, y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
